{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd ## for dataset and eda\n",
    "import numpy as np ## for eda\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "print(\"All good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages are imported\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer # do not forget to conda install transformers\n",
    "print(\"All packages are imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU usage is set up: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"GPU usage is set up: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Bucket: firstprojectdl>\n",
      "Great, we now have access to our first bucket on google cloud storage where we put our data\n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"firstprojectdl\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "print(bucket)\n",
    "print('Great, we now have access to our first bucket on google cloud storage where we put our data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/hw2/\n",
      "data/hw2/nodeid2paperid.csv\n",
      "nodeid2paperid.csv\n",
      "data/hw2/sample.csv\n",
      "sample.csv\n",
      "data/hw2/testData.csv\n",
      "testData.csv\n",
      "data/hw2/textData.csv\n",
      "textData.csv\n",
      "data/hw2/trainData.csv\n",
      "trainData.csv\n",
      "we imported the trainData.csv successfully\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "\n",
    "bucket_name = \"firstprojectdl\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "# When you have your files in a subfolder of the bucket.\n",
    "my_prefix = \"data/hw2/\" # the name of the subfolder\n",
    "blobs = bucket.list_blobs(prefix = my_prefix, delimiter = '/')\n",
    "\n",
    "\n",
    "for blob in blobs:\n",
    "    print(blob.name)\n",
    "    if(blob.name != my_prefix): # ignoring the subfolder itself \n",
    "        file_name = blob.name.replace(my_prefix, \"\")\n",
    "        blob.download_to_filename(file_name) # download the file to the machine\n",
    "        print(file_name)\n",
    "print(f\"we imported the {file_name} successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paper id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104447</td>\n",
       "      <td>630234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15858</td>\n",
       "      <td>803423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107156</td>\n",
       "      <td>1102481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82077</td>\n",
       "      <td>1810480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42436</td>\n",
       "      <td>2131697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  paper id\n",
       "0  104447    630234\n",
       "1   15858    803423\n",
       "2  107156   1102481\n",
       "3   82077   1810480\n",
       "4   42436   2131697"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodeid2paperid = pd.read_csv('nodeid2paperid.csv')\n",
    "nodeid2paperid.head()\n",
    "nodeid2paperid.rename(columns={'node idx': 'id'}, inplace=True)\n",
    "nodeid2paperid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id\n",
       "0  137832\n",
       "1  137833\n",
       "2  137834\n",
       "3  137836\n",
       "4  137837"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('testData.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13718, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630234</td>\n",
       "      <td>spreadsheets on the move an evaluation of mobi...</td>\n",
       "      <td>The power of mobile devices has increased dram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>803423</td>\n",
       "      <td>multi view metric learning for multi view vide...</td>\n",
       "      <td>Traditional methods on video summarization are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1102481</td>\n",
       "      <td>big data analytics in future internet of things</td>\n",
       "      <td>Current research on Internet of Things (IoT) m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1810480</td>\n",
       "      <td>cryptographic hardening of d sequences</td>\n",
       "      <td>This paper shows how a one-way mapping using m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2131697</td>\n",
       "      <td>gesture based continuous authentication for we...</td>\n",
       "      <td>We study the feasibility of touch gesture beha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper id                                              title  \\\n",
       "0    630234  spreadsheets on the move an evaluation of mobi...   \n",
       "1    803423  multi view metric learning for multi view vide...   \n",
       "2   1102481    big data analytics in future internet of things   \n",
       "3   1810480             cryptographic hardening of d sequences   \n",
       "4   2131697  gesture based continuous authentication for we...   \n",
       "\n",
       "                                            abstract  \n",
       "0  The power of mobile devices has increased dram...  \n",
       "1  Traditional methods on video summarization are...  \n",
       "2  Current research on Internet of Things (IoT) m...  \n",
       "3  This paper shows how a one-way mapping using m...  \n",
       "4  We study the feasibility of touch gesture beha...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.read_csv('textData.csv')\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73718, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  id\n",
       "0      4   0\n",
       "1      5   1\n",
       "2      8   3\n",
       "3      6   6\n",
       "4      4   7"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('trainData.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  label\n",
       "0  137832      0\n",
       "1  137833      0\n",
       "2  137834      0\n",
       "3  137836      0\n",
       "4  137837      0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('sample.csv')\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13718, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us merge text in train and test\n",
    "# train\n",
    "trainData = pd.merge(train, nodeid2paperid, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.merge(trainData, text, on ='paper id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>paper id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9657784</td>\n",
       "      <td>evasion attacks against machine learning at te...</td>\n",
       "      <td>In security-sensitive applications, the succes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>39886162</td>\n",
       "      <td>how hard is computing parity with noisy commun...</td>\n",
       "      <td>We show a tight lower bound of $\\Omega(N \\log\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>121432379</td>\n",
       "      <td>a promise theory perspective on data networks</td>\n",
       "      <td>Networking is undergoing a transformation thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1444859417</td>\n",
       "      <td>webvrgis based city bigdata 3d visualization a...</td>\n",
       "      <td>This paper shows the WEBVRGIS platform overlyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1483430697</td>\n",
       "      <td>information theoretic authentication and secre...</td>\n",
       "      <td>In the splitting model, information theoretic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  id    paper id                                              title  \\\n",
       "0      4   0     9657784  evasion attacks against machine learning at te...   \n",
       "1      5   1    39886162  how hard is computing parity with noisy commun...   \n",
       "2      8   3   121432379      a promise theory perspective on data networks   \n",
       "3      6   6  1444859417  webvrgis based city bigdata 3d visualization a...   \n",
       "4      4   7  1483430697  information theoretic authentication and secre...   \n",
       "\n",
       "                                            abstract  \n",
       "0  In security-sensitive applications, the succes...  \n",
       "1  We show a tight lower bound of $\\Omega(N \\log\\...  \n",
       "2  Networking is undergoing a transformation thro...  \n",
       "3  This paper shows the WEBVRGIS platform overlyi...  \n",
       "4  In the splitting model, information theoretic ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "testData = pd.merge(test, nodeid2paperid, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paper id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137832</td>\n",
       "      <td>2403725649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137833</td>\n",
       "      <td>2404740077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137834</td>\n",
       "      <td>2407125866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137836</td>\n",
       "      <td>2408327416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137837</td>\n",
       "      <td>2412021890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    paper id\n",
       "0  137832  2403725649\n",
       "1  137833  2404740077\n",
       "2  137834  2407125866\n",
       "3  137836  2408327416\n",
       "4  137837  2412021890"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.merge(testData, text, on ='paper id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paper id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137832</td>\n",
       "      <td>2403725649</td>\n",
       "      <td>patchlift fast and exact computation of patch ...</td>\n",
       "      <td>In this paper, we propose a fast algorithm cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137833</td>\n",
       "      <td>2404740077</td>\n",
       "      <td>the unreasonable effectiveness of address clus...</td>\n",
       "      <td>Address clustering tries to construct the one-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137834</td>\n",
       "      <td>2407125866</td>\n",
       "      <td>end to end goal driven web navigation</td>\n",
       "      <td>We propose a goal-driven web navigation as a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137836</td>\n",
       "      <td>2408327416</td>\n",
       "      <td>complexity measures for map reduce and compari...</td>\n",
       "      <td>The programming paradigm Map-Reduce and its ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137837</td>\n",
       "      <td>2412021890</td>\n",
       "      <td>a parallel implementation of the ensemble kalm...</td>\n",
       "      <td>This paper discusses an efficient parallel imp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    paper id                                              title  \\\n",
       "0  137832  2403725649  patchlift fast and exact computation of patch ...   \n",
       "1  137833  2404740077  the unreasonable effectiveness of address clus...   \n",
       "2  137834  2407125866              end to end goal driven web navigation   \n",
       "3  137836  2408327416  complexity measures for map reduce and compari...   \n",
       "4  137837  2412021890  a parallel implementation of the ensemble kalm...   \n",
       "\n",
       "                                            abstract  \n",
       "0  In this paper, we propose a fast algorithm cal...  \n",
       "1  Address clustering tries to construct the one-...  \n",
       "2  We propose a goal-driven web navigation as a b...  \n",
       "3  The programming paradigm Map-Reduce and its ma...  \n",
       "4  This paper discusses an efficient parallel imp...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13718, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>evasion attacks against machine learning at te...</td>\n",
       "      <td>In security-sensitive applications, the succes...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>how hard is computing parity with noisy commun...</td>\n",
       "      <td>We show a tight lower bound of $\\Omega(N \\log\\...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a promise theory perspective on data networks</td>\n",
       "      <td>Networking is undergoing a transformation thro...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>webvrgis based city bigdata 3d visualization a...</td>\n",
       "      <td>This paper shows the WEBVRGIS platform overlyi...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>information theoretic authentication and secre...</td>\n",
       "      <td>In the splitting model, information theoretic ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  evasion attacks against machine learning at te...   \n",
       "1   1  how hard is computing parity with noisy commun...   \n",
       "2   3      a promise theory perspective on data networks   \n",
       "3   6  webvrgis based city bigdata 3d visualization a...   \n",
       "4   7  information theoretic authentication and secre...   \n",
       "\n",
       "                                            abstract  label  \n",
       "0  In security-sensitive applications, the succes...      4  \n",
       "1  We show a tight lower bound of $\\Omega(N \\log\\...      5  \n",
       "2  Networking is undergoing a transformation thro...      8  \n",
       "3  This paper shows the WEBVRGIS platform overlyi...      6  \n",
       "4  In the splitting model, information theoretic ...      4  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Removing unwanted columns and only leaving title and abstract of the scientific article and the category which will be the label\n",
    "trainData = trainData[['id','title', 'abstract', 'label']]\n",
    "labelListData = list(trainData['label'].unique())\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137832</td>\n",
       "      <td>patchlift fast and exact computation of patch ...</td>\n",
       "      <td>In this paper, we propose a fast algorithm cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137833</td>\n",
       "      <td>the unreasonable effectiveness of address clus...</td>\n",
       "      <td>Address clustering tries to construct the one-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137834</td>\n",
       "      <td>end to end goal driven web navigation</td>\n",
       "      <td>We propose a goal-driven web navigation as a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137836</td>\n",
       "      <td>complexity measures for map reduce and compari...</td>\n",
       "      <td>The programming paradigm Map-Reduce and its ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137837</td>\n",
       "      <td>a parallel implementation of the ensemble kalm...</td>\n",
       "      <td>This paper discusses an efficient parallel imp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  137832  patchlift fast and exact computation of patch ...   \n",
       "1  137833  the unreasonable effectiveness of address clus...   \n",
       "2  137834              end to end goal driven web navigation   \n",
       "3  137836  complexity measures for map reduce and compari...   \n",
       "4  137837  a parallel implementation of the ensemble kalm...   \n",
       "\n",
       "                                            abstract  \n",
       "0  In this paper, we propose a fast algorithm cal...  \n",
       "1  Address clustering tries to construct the one-...  \n",
       "2  We propose a goal-driven web navigation as a b...  \n",
       "3  The programming paradigm Map-Reduce and its ma...  \n",
       "4  This paper discusses an efficient parallel imp...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = testData[['id','title', 'abstract']]\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge the title and abstract columns together \n",
    "# trainData['description'] = trainData['title'].str.cat(trainData['abstract'],sep=\" \")\n",
    "trainData['description'] = trainData['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words in description and title ## Actually mention why you may not want to remove stop words: https://stackoverflow.com/questions/63633534/is-it-necessary-to-do-stopwords-removal-stemming-lemmatization-for-text-classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainData[['description', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description    0\n",
       "label          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labelListData) # 20 labels and not 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 8, 6, 3, 16, 19, 14, 10, 0, 2, 18, 9, 13, 11, 1, 7, 15, 17, 12]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelListData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# biggest text in column\n",
    "trainData['description'].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evasion attacks against machine learning at te...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how hard is computing parity with noisy commun...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a promise theory perspective on data networks</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>webvrgis based city bigdata 3d visualization a...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>information theoretic authentication and secre...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>incentivizing users of data centers participat...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>semantic change detection with hypermaps</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>computing with polynomial ordinary differentia...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>on energy efficiency in wireless networks a ga...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>incorporating quotation and evaluation into ch...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  label\n",
       "0      evasion attacks against machine learning at te...      4\n",
       "1      how hard is computing parity with noisy commun...      5\n",
       "2          a promise theory perspective on data networks      8\n",
       "3      webvrgis based city bigdata 3d visualization a...      6\n",
       "4      information theoretic authentication and secre...      4\n",
       "...                                                  ...    ...\n",
       "59995  incentivizing users of data centers participat...      5\n",
       "59996           semantic change detection with hypermaps     16\n",
       "59997  computing with polynomial ordinary differentia...      9\n",
       "59998  on energy efficiency in wireless networks a ga...      8\n",
       "59999  incorporating quotation and evaluation into ch...      2\n",
       "\n",
       "[60000 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testData['description'] = testData['title'].str.cat(testData['abstract'],sep=\" \")\n",
    "testData['description'] = testData['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137832</td>\n",
       "      <td>patchlift fast and exact computation of patch ...</td>\n",
       "      <td>In this paper, we propose a fast algorithm cal...</td>\n",
       "      <td>patchlift fast and exact computation of patch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137833</td>\n",
       "      <td>the unreasonable effectiveness of address clus...</td>\n",
       "      <td>Address clustering tries to construct the one-...</td>\n",
       "      <td>the unreasonable effectiveness of address clus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137834</td>\n",
       "      <td>end to end goal driven web navigation</td>\n",
       "      <td>We propose a goal-driven web navigation as a b...</td>\n",
       "      <td>end to end goal driven web navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137836</td>\n",
       "      <td>complexity measures for map reduce and compari...</td>\n",
       "      <td>The programming paradigm Map-Reduce and its ma...</td>\n",
       "      <td>complexity measures for map reduce and compari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137837</td>\n",
       "      <td>a parallel implementation of the ensemble kalm...</td>\n",
       "      <td>This paper discusses an efficient parallel imp...</td>\n",
       "      <td>a parallel implementation of the ensemble kalm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13713</th>\n",
       "      <td>169336</td>\n",
       "      <td>confidence guided stereo 3d object detection w...</td>\n",
       "      <td>Accurate and reliable 3D object detection is v...</td>\n",
       "      <td>confidence guided stereo 3d object detection w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13714</th>\n",
       "      <td>169338</td>\n",
       "      <td>sentinet detecting localized universal attacks...</td>\n",
       "      <td>SentiNet is a novel detection framework for lo...</td>\n",
       "      <td>sentinet detecting localized universal attacks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13715</th>\n",
       "      <td>169340</td>\n",
       "      <td>learning compositional rules via neural progra...</td>\n",
       "      <td>Many aspects of human reasoning, including lan...</td>\n",
       "      <td>learning compositional rules via neural progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13716</th>\n",
       "      <td>169341</td>\n",
       "      <td>certified defenses for adversarial patches</td>\n",
       "      <td>Adversarial patch attacks are among one of the...</td>\n",
       "      <td>certified defenses for adversarial patches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13717</th>\n",
       "      <td>169342</td>\n",
       "      <td>fauras a proxy based framework for ensuring th...</td>\n",
       "      <td>HTTP/2 video streaming has caught a lot of att...</td>\n",
       "      <td>fauras a proxy based framework for ensuring th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13718 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0      137832  patchlift fast and exact computation of patch ...   \n",
       "1      137833  the unreasonable effectiveness of address clus...   \n",
       "2      137834              end to end goal driven web navigation   \n",
       "3      137836  complexity measures for map reduce and compari...   \n",
       "4      137837  a parallel implementation of the ensemble kalm...   \n",
       "...       ...                                                ...   \n",
       "13713  169336  confidence guided stereo 3d object detection w...   \n",
       "13714  169338  sentinet detecting localized universal attacks...   \n",
       "13715  169340  learning compositional rules via neural progra...   \n",
       "13716  169341         certified defenses for adversarial patches   \n",
       "13717  169342  fauras a proxy based framework for ensuring th...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      In this paper, we propose a fast algorithm cal...   \n",
       "1      Address clustering tries to construct the one-...   \n",
       "2      We propose a goal-driven web navigation as a b...   \n",
       "3      The programming paradigm Map-Reduce and its ma...   \n",
       "4      This paper discusses an efficient parallel imp...   \n",
       "...                                                  ...   \n",
       "13713  Accurate and reliable 3D object detection is v...   \n",
       "13714  SentiNet is a novel detection framework for lo...   \n",
       "13715  Many aspects of human reasoning, including lan...   \n",
       "13716  Adversarial patch attacks are among one of the...   \n",
       "13717  HTTP/2 video streaming has caught a lot of att...   \n",
       "\n",
       "                                             description  \n",
       "0      patchlift fast and exact computation of patch ...  \n",
       "1      the unreasonable effectiveness of address clus...  \n",
       "2                  end to end goal driven web navigation  \n",
       "3      complexity measures for map reduce and compari...  \n",
       "4      a parallel implementation of the ensemble kalm...  \n",
       "...                                                  ...  \n",
       "13713  confidence guided stereo 3d object detection w...  \n",
       "13714  sentinet detecting localized universal attacks...  \n",
       "13715  learning compositional rules via neural progra...  \n",
       "13716         certified defenses for adversarial patches  \n",
       "13717  fauras a proxy based framework for ensuring th...  \n",
       "\n",
       "[13718 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = testData[['description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patchlift fast and exact computation of patch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the unreasonable effectiveness of address clus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>end to end goal driven web navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complexity measures for map reduce and compari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a parallel implementation of the ensemble kalm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13713</th>\n",
       "      <td>confidence guided stereo 3d object detection w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13714</th>\n",
       "      <td>sentinet detecting localized universal attacks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13715</th>\n",
       "      <td>learning compositional rules via neural progra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13716</th>\n",
       "      <td>certified defenses for adversarial patches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13717</th>\n",
       "      <td>fauras a proxy based framework for ensuring th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13718 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description\n",
       "0      patchlift fast and exact computation of patch ...\n",
       "1      the unreasonable effectiveness of address clus...\n",
       "2                  end to end goal driven web navigation\n",
       "3      complexity measures for map reduce and compari...\n",
       "4      a parallel implementation of the ensemble kalm...\n",
       "...                                                  ...\n",
       "13713  confidence guided stereo 3d object detection w...\n",
       "13714  sentinet detecting localized universal attacks...\n",
       "13715  learning compositional rules via neural progra...\n",
       "13716         certified defenses for adversarial patches\n",
       "13717  fauras a proxy based framework for ensuring th...\n",
       "\n",
       "[13718 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# biggest text in column\n",
    "testData['description'].apply(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 2e-05\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        description = str(self.data.description[index])\n",
    "        description = \" \".join(description.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            description,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.label[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (60000, 2)\n",
      "TRAIN Dataset: (48000, 2)\n",
      "VALIDATION Dataset: (12000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "train_size = 0.8\n",
    "train_dataset= trainData.sample(frac=train_size,random_state=200)\n",
    "val_dataset= trainData.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(train.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"VALIDATION Dataset: {}\".format(val_dataset.shape))\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "validation_set = Triage(val_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "val_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validation_loader = DataLoader(validation_set, **val_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class DistilBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistilBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcuate the accuracy of the model\n",
    "\n",
    "def calculate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "        outputs = model(ids, mask)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calculate_accu(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _%1000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 1000 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 1000 steps: {accu_step}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 1000 steps: 3.043318748474121\n",
      "Training Accuracy per 1000 steps: 6.25\n",
      "Training Loss per 1000 steps: 1.2744178297398212\n",
      "Training Accuracy per 1000 steps: 64.16396103896103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [17:38<1:10:32, 1058.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 66.59166666666667\n",
      "Training Loss Epoch: 1.1726985195875168\n",
      "Training Accuracy Epoch: 66.59166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 1000 steps: 0.7455750107765198\n",
      "Training Accuracy per 1000 steps: 71.875\n",
      "Training Loss per 1000 steps: 0.7732596465579041\n",
      "Training Accuracy per 1000 steps: 76.90434565434566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [35:31<53:08, 1062.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 77.12083333333334\n",
      "Training Loss Epoch: 0.7671007470885912\n",
      "Training Accuracy Epoch: 77.12083333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 1000 steps: 0.6575074791908264\n",
      "Training Accuracy per 1000 steps: 81.25\n",
      "Training Loss per 1000 steps: 0.5836289070256344\n",
      "Training Accuracy per 1000 steps: 82.54557942057941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [53:25<35:32, 1066.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 82.40208333333334\n",
      "Training Loss Epoch: 0.5856876086890698\n",
      "Training Accuracy Epoch: 82.40208333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 1000 steps: 0.35886019468307495\n",
      "Training Accuracy per 1000 steps: 81.25\n",
      "Training Loss per 1000 steps: 0.43405916745756773\n",
      "Training Accuracy per 1000 steps: 86.86001498501498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [1:11:20<17:48, 1068.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 86.75625\n",
      "Training Loss Epoch: 0.43820720253884793\n",
      "Training Accuracy Epoch: 86.75625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 1000 steps: 0.4278838634490967\n",
      "Training Accuracy per 1000 steps: 87.5\n",
      "Training Loss per 1000 steps: 0.3162710902082932\n",
      "Training Accuracy per 1000 steps: 90.57192807192807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [1:29:17<00:00, 1071.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 90.35833333333333\n",
      "Training Loss Epoch: 0.32167828488349914\n",
      "Training Accuracy Epoch: 90.35833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(epoch):\n",
    "    model.eval()\n",
    "    tr_loss = 0\n",
    "    nb_tr_steps = 0\n",
    "    n_correct = 0 \n",
    "    nb_tr_examples = 0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(validation_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask).squeeze()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calculate_accu(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            if _%1000==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 1000 steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per 1000 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return epoch_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2074: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss per 1000 steps: 0.7389875054359436\n",
      "Validation Accuracy per 1000 steps: 81.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [01:35<06:20, 95.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 0.8925721027056376\n",
      "Validation Accuracy Epoch: 75.81666666666666\n",
      "Accuracy on test data = 75.82%\n",
      "Validation Loss per 1000 steps: 1.2503362894058228\n",
      "Validation Accuracy per 1000 steps: 68.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [03:09<04:44, 94.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 0.8925721096992493\n",
      "Validation Accuracy Epoch: 75.81666666666666\n",
      "Accuracy on test data = 75.82%\n",
      "Validation Loss per 1000 steps: 1.092687726020813\n",
      "Validation Accuracy per 1000 steps: 78.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [04:44<03:09, 94.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 0.8925721114873886\n",
      "Validation Accuracy Epoch: 75.81666666666666\n",
      "Accuracy on test data = 75.82%\n",
      "Validation Loss per 1000 steps: 0.7300519943237305\n",
      "Validation Accuracy per 1000 steps: 75.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [06:19<01:34, 94.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 0.8925721105734508\n",
      "Validation Accuracy Epoch: 75.81666666666666\n",
      "Accuracy on test data = 75.82%\n",
      "Validation Loss per 1000 steps: 0.9180948138237\n",
      "Validation Accuracy per 1000 steps: 78.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [07:54<00:00, 94.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 0.8925721062421799\n",
      "Validation Accuracy Epoch: 75.81666666666666\n",
      "Accuracy on test data = 75.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    acc = valid(epoch)\n",
    "    print(\"Accuracy on test data = %0.2f%%\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriageTest(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        description = str(self.data.description[index])\n",
    "        description = \" \".join(description.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            description,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = TriageTest(testData, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {'batch_size': 32,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "\n",
    "testing_loader = DataLoader(testSet, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "429it [01:38,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        predictions.append(big_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([16,  8, 10,  5, 19, 15,  4,  5,  8,  8, 16, 10,  9,  0, 16, 10, 16, 16,\n",
      "         2, 16, 16, 16, 19, 19, 11,  8, 18, 16, 16, 10, 16, 16],\n",
      "       device='cuda:0'), tensor([10, 16, 16, 16,  8, 19,  2, 19, 16, 16,  8,  8, 14, 16,  8, 16,  6,  7,\n",
      "         1, 16, 16,  4, 13,  9, 19,  8,  4,  3, 16, 16,  5, 16],\n",
      "       device='cuda:0'), tensor([16,  4,  5,  2, 16, 10,  2, 16,  2, 19,  7,  4,  4, 10, 11, 16, 10, 16,\n",
      "        19, 16, 16,  9,  4, 16, 19, 16,  2, 13,  3,  8, 16,  5],\n",
      "       device='cuda:0'), tensor([16,  8,  7,  4, 13, 16,  8, 16, 16, 10,  4,  2, 16,  4, 10, 16,  2, 16,\n",
      "        10, 16, 16, 10, 16,  8,  2, 16, 16, 16, 16, 16, 16,  5],\n",
      "       device='cuda:0'), tensor([ 6, 16, 13,  5,  4,  0,  5, 16,  8,  3, 16,  5, 16, 16, 15, 16,  2, 10,\n",
      "        16, 16, 16, 10, 16, 13,  0, 18, 16,  4,  2, 10, 10, 16],\n",
      "       device='cuda:0'), tensor([ 8, 16, 16, 16, 16, 16, 16, 16, 16,  5,  8,  8,  8, 15,  3, 16,  5, 16,\n",
      "         3, 16, 16, 13, 16, 10, 16, 17, 16, 16, 16,  3, 16,  8],\n",
      "       device='cuda:0'), tensor([ 4, 16, 16, 16, 19, 16,  2, 16, 16, 10, 16, 16,  8, 16,  4, 19, 16, 16,\n",
      "         4, 16,  4,  8,  9, 16, 13,  6,  8, 16, 16,  4, 16, 11],\n",
      "       device='cuda:0'), tensor([ 2, 16, 16, 16, 16,  4,  4, 16, 16, 19, 16,  7, 16, 16, 16, 16, 16,  4,\n",
      "        13, 11, 16,  2, 16,  4,  4,  5, 13,  2, 16, 11, 16, 16],\n",
      "       device='cuda:0'), tensor([ 8,  8,  4,  4, 16,  8, 11, 10, 16,  9, 16,  8,  9,  5, 16,  9, 10, 16,\n",
      "        16, 16,  2, 11, 16, 16, 19, 16, 10,  4, 16,  2, 10,  3],\n",
      "       device='cuda:0'), tensor([ 3, 16,  8,  5, 16,  8,  5, 11, 16,  5, 16, 16, 17, 16, 10, 10, 19,  2,\n",
      "        19,  2, 11, 16,  2, 13, 11, 15,  2, 13, 16,  4, 10, 16],\n",
      "       device='cuda:0'), tensor([ 2,  2, 10,  9,  8, 16, 16,  3,  2, 10,  5, 10,  6, 13,  4,  9, 16,  4,\n",
      "        10,  2,  8, 16, 10, 16,  8,  5,  5, 16,  5,  5, 16,  5],\n",
      "       device='cuda:0'), tensor([16, 19, 16, 16,  9,  3, 10,  5,  2, 16,  8,  5, 10, 10, 13, 16, 17, 16,\n",
      "        16, 16, 16,  2,  8,  8,  9, 16, 16, 16, 11,  8,  4,  8],\n",
      "       device='cuda:0'), tensor([16, 11, 16, 16, 15, 16,  4,  8, 16,  0, 16,  5, 16,  6,  4, 16, 16, 10,\n",
      "        10,  8,  4, 10, 16, 16, 13, 16, 16, 16,  8, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 3,  1, 16,  4, 10, 16, 16, 16,  5, 10, 10, 16, 10, 10, 16, 16, 16, 16,\n",
      "        16, 16,  4, 16,  6,  3,  8, 16, 10, 16, 10,  2, 16,  5],\n",
      "       device='cuda:0'), tensor([16,  4,  9, 15, 16, 16,  9,  2,  4,  9, 13, 13, 16, 16,  2,  5,  8, 16,\n",
      "        16,  4,  5,  5,  5, 16, 16,  5,  4, 16, 16, 17, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  9,  2, 15,  6, 10, 13,  9,  2,  8,  8, 16,  8,  4,  8, 10,  4, 10,\n",
      "         4, 13, 10,  4,  2, 14,  2,  0, 19,  8, 13,  5,  6,  6],\n",
      "       device='cuda:0'), tensor([16,  3,  6, 11,  8,  9, 16,  4, 16, 19,  2,  2,  8, 16,  4,  8,  8,  2,\n",
      "         8, 15, 10,  8, 16,  8,  6,  4,  4, 10,  2, 10,  2,  2],\n",
      "       device='cuda:0'), tensor([13,  8,  4,  8,  2,  4, 13,  9,  5, 18,  4,  4,  8,  8,  6,  8,  9,  8,\n",
      "        10,  5,  9, 16,  0, 16, 18,  2,  0, 16, 16, 19,  6,  4],\n",
      "       device='cuda:0'), tensor([ 4,  8,  4, 10,  8,  5,  3, 16,  4,  0,  3, 19, 18, 19, 13, 19,  2, 16,\n",
      "         2, 16, 16,  4,  8, 19,  8,  4,  8, 16, 13,  9,  8, 16],\n",
      "       device='cuda:0'), tensor([16, 10, 16,  4, 16, 16, 16,  8, 16, 16, 16, 16,  3, 16, 16,  5,  5, 16,\n",
      "        10, 16,  9, 16,  6, 10, 19,  3, 16,  3,  5,  3,  2,  5],\n",
      "       device='cuda:0'), tensor([ 3, 16,  3, 16, 16, 16, 16, 16, 16, 10, 19, 13, 16, 16,  8, 18, 16, 19,\n",
      "         2,  5,  6, 16, 19, 16,  8, 14, 16,  4,  2,  5,  4, 16],\n",
      "       device='cuda:0'), tensor([16,  6,  6, 10, 16,  4,  5, 16, 15, 16, 16, 16, 16, 16, 16,  5, 10, 13,\n",
      "        16, 10, 16, 16, 19,  9, 16, 16,  7, 16, 16, 19,  6, 16],\n",
      "       device='cuda:0'), tensor([19,  5, 10, 19,  4,  5, 16, 16,  2, 15, 16, 16,  8, 16, 16, 13, 16,  2,\n",
      "        16, 16, 16, 18,  9, 16,  5, 16,  6, 16,  2,  4, 13, 16],\n",
      "       device='cuda:0'), tensor([16,  5, 16, 19, 16, 16,  8, 16, 10, 16, 10, 13,  5, 16, 13, 16, 16, 16,\n",
      "        19, 16, 16, 10, 16, 16, 16, 16,  3,  4, 16, 16,  2, 16],\n",
      "       device='cuda:0'), tensor([ 8, 16, 16,  5, 13, 16, 10,  8, 16,  8, 16, 16,  8, 16, 16,  6,  1, 16,\n",
      "         4, 10, 11, 13, 16,  2, 16, 16, 16, 16, 16, 16, 16,  5],\n",
      "       device='cuda:0'), tensor([16,  5, 16,  6, 16,  8, 16, 16, 16, 19, 16, 11,  8, 16, 16,  8, 13,  4,\n",
      "         5, 16,  8,  9, 10,  5,  4,  2, 10,  8, 10, 16,  4,  8],\n",
      "       device='cuda:0'), tensor([19,  4,  5, 10,  9,  8,  2, 10, 15, 16, 10,  0,  8,  3, 19,  7,  4,  0,\n",
      "         9,  4,  4, 16, 16, 10,  5, 16, 13,  8,  5,  9, 19, 10],\n",
      "       device='cuda:0'), tensor([17,  2, 16,  5, 16, 16, 16, 10, 16, 16, 16,  5,  3,  4,  9, 16, 16,  5,\n",
      "        16,  9, 10, 19,  2,  4, 10,  8,  4, 10,  8,  5,  8,  4],\n",
      "       device='cuda:0'), tensor([13, 16, 10,  4, 16, 16,  3, 16, 16,  4,  4, 16, 17, 16, 16,  5,  8, 19,\n",
      "        16, 10, 16, 19, 16, 16, 16, 19, 10, 10,  3,  8,  6, 15],\n",
      "       device='cuda:0'), tensor([ 4, 16,  6,  2, 19,  8,  9,  7, 16,  2, 19, 16, 10,  8,  0,  2,  8,  9,\n",
      "         8, 14, 10, 16, 16, 16, 16, 10,  3,  6, 16,  3, 16,  9],\n",
      "       device='cuda:0'), tensor([ 4,  6, 16, 16,  9, 16,  4, 16, 16, 16,  4,  4, 16,  2, 16, 16, 16,  4,\n",
      "        16, 11,  8, 16, 16, 16, 16,  4,  5, 16, 16, 16,  4, 10],\n",
      "       device='cuda:0'), tensor([ 4, 16,  4, 10, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16,  5,  8, 16,\n",
      "        16,  5, 16, 16, 16,  5, 16,  2, 16,  8, 16,  6, 16, 10],\n",
      "       device='cuda:0'), tensor([ 4,  2,  8, 10, 16,  5, 16,  9, 16, 16, 16, 10, 16,  4,  8,  4,  3, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 10,  1,  8,  1,  8, 19],\n",
      "       device='cuda:0'), tensor([13,  8, 10,  4,  3,  8, 13,  4,  4, 16, 14,  4, 16,  5,  3,  8,  3,  8,\n",
      "         9, 16,  9,  6,  5, 16, 17,  3, 10, 15, 16,  3,  3, 10],\n",
      "       device='cuda:0'), tensor([16,  3, 10,  5,  4,  2, 10,  2,  1, 16, 14,  5, 11,  8, 14,  5, 16,  7,\n",
      "        18, 10, 19, 10,  5,  2,  7,  6,  4,  0,  8,  8,  8, 11],\n",
      "       device='cuda:0'), tensor([ 2,  2, 16,  9, 10, 10,  8, 11,  5,  4, 10,  5, 16,  5, 19,  3, 19, 10,\n",
      "        10,  2,  2, 16, 10, 16, 19, 18, 11,  4, 19,  5,  5,  9],\n",
      "       device='cuda:0'), tensor([ 8, 16,  9,  8,  4, 16,  7, 16,  2,  7,  4, 16, 16,  5, 10,  8, 16, 10,\n",
      "        16, 16,  8, 10,  4, 10,  5, 16, 18, 10, 16,  5, 13,  5],\n",
      "       device='cuda:0'), tensor([ 7,  1,  8,  4,  2, 16, 16, 16, 16, 10,  3,  4,  2,  5,  5, 16,  5, 16,\n",
      "        16,  8, 16,  8, 16, 16,  5,  4, 10, 13, 16,  5, 16, 16],\n",
      "       device='cuda:0'), tensor([ 5,  5, 16, 16, 16, 16,  9,  4,  5, 16, 16,  5, 10, 13,  4, 16, 16, 16,\n",
      "         8,  8, 10, 16, 18, 19, 16, 16, 16,  3, 16, 16, 13, 16],\n",
      "       device='cuda:0'), tensor([16,  4, 16, 16,  4, 16,  3,  8, 16, 16,  8,  1,  4,  8, 16, 10,  5, 16,\n",
      "        16, 16, 16,  5, 19, 16, 16, 16,  4,  4, 16,  8, 16, 16],\n",
      "       device='cuda:0'), tensor([ 5, 16,  4, 16, 16,  4, 16,  4, 16, 10,  3,  5,  6,  5, 11,  3, 16, 16,\n",
      "        16, 16,  8, 16, 16,  8,  1,  8, 19, 16, 19,  4,  3, 16],\n",
      "       device='cuda:0'), tensor([10, 16, 13, 16,  0, 16, 16, 16, 16, 19,  4, 16, 16, 16,  3,  6,  5, 18,\n",
      "        10, 16, 10,  2, 16,  4, 16,  5,  5, 16,  4, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 10, 16, 16, 16,  8, 16,  5, 16, 19, 10,  4,  7, 19, 16,  2,  8, 16,\n",
      "        16,  4, 16, 10,  3, 16, 16,  6, 10, 19, 16, 10, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 10, 16, 16, 16,  5, 16, 16,  2,  7, 16,  5,  4, 15, 19, 16, 16, 19,\n",
      "         3, 10, 16,  8,  8,  2,  8,  3, 16, 16, 14, 10, 10, 19],\n",
      "       device='cuda:0'), tensor([19, 16,  8,  8,  8,  2, 10, 10, 16, 16,  4, 10, 10,  3, 16, 16,  9, 10,\n",
      "        16,  8, 16, 16,  8, 11, 16, 10,  6, 16, 13,  8,  5, 13],\n",
      "       device='cuda:0'), tensor([ 9,  5, 16,  8, 16, 16, 10,  2,  2, 10,  4, 16, 16, 16,  4,  5, 10, 16,\n",
      "        13, 10,  4, 16,  9,  5, 18, 16,  8, 16, 10,  2, 13, 13],\n",
      "       device='cuda:0'), tensor([ 4, 11,  2, 16, 19, 16, 13,  2, 16,  8,  5, 10,  8, 10,  8, 19, 16, 10,\n",
      "         5, 16, 16, 16, 16, 16,  8, 10, 16,  8,  8,  3, 16,  8],\n",
      "       device='cuda:0'), tensor([16,  8, 16,  5, 19,  8, 16, 16,  5, 16,  4,  4, 16, 16, 14, 10,  4, 16,\n",
      "        10, 16,  5,  8, 19, 16,  3, 16, 16, 10, 10,  8, 16, 16],\n",
      "       device='cuda:0'), tensor([ 5, 16, 16, 16, 19, 10, 19,  9,  4,  3,  4, 16,  6,  5,  3,  4,  4, 16,\n",
      "        16, 16, 16, 10, 16,  2,  8, 15,  8,  3, 16, 16, 16, 10],\n",
      "       device='cuda:0'), tensor([16, 16, 16,  5,  8, 19, 15,  3, 10, 13, 19, 16, 16,  5,  8, 16, 17,  4,\n",
      "         8, 10, 16, 13, 16, 16,  4, 10, 16, 16, 16, 16,  5, 16],\n",
      "       device='cuda:0'), tensor([10, 16, 16, 16,  7,  4, 15,  7, 16, 16, 16,  3,  4, 16, 13,  8,  4,  9,\n",
      "        16,  4, 16,  2, 16, 10,  4, 16, 16,  9, 16, 16, 10,  5],\n",
      "       device='cuda:0'), tensor([ 5,  2,  4,  4,  9,  5,  2,  9, 10,  8,  8, 10,  2, 13,  3,  4, 18, 13,\n",
      "        16, 10, 16,  2,  4,  4,  6,  0,  2, 16, 16,  5,  0, 16],\n",
      "       device='cuda:0'), tensor([ 1, 16, 10,  4, 16, 10,  9,  4, 16,  9, 13,  0,  5, 19, 10, 10, 14,  2,\n",
      "         5,  8, 19,  8, 16, 19,  5,  8,  8,  4,  2, 18, 16, 19],\n",
      "       device='cuda:0'), tensor([ 9,  3,  3,  4, 13,  8,  8, 16, 10,  2, 16, 16,  2,  2,  3, 16, 13,  5,\n",
      "         2,  5,  4, 10, 14,  9, 10, 19,  7,  2, 16,  4,  4, 16],\n",
      "       device='cuda:0'), tensor([ 1, 16, 16, 16, 16, 16, 10, 16,  5, 13,  8, 14,  8, 14, 10, 10, 16, 16,\n",
      "        10,  9,  8, 13, 10,  3,  2, 10,  8, 18, 19, 16, 19,  8],\n",
      "       device='cuda:0'), tensor([16, 10, 16, 10, 16,  2, 16,  8, 11,  6, 16,  9, 11,  9, 16, 16,  5, 16,\n",
      "        10, 10, 13, 10, 16, 16,  4, 16,  4, 16, 10, 16, 13, 16],\n",
      "       device='cuda:0'), tensor([16,  5, 16,  5, 10, 16, 16, 16,  8, 10, 10,  7,  2, 10, 11, 19,  8, 16,\n",
      "        19, 16, 16,  4, 16, 16, 16, 10,  8, 16, 10, 16, 16,  3],\n",
      "       device='cuda:0'), tensor([ 4,  8, 16,  4, 16, 10, 10,  5,  5,  4, 16,  5, 15, 11, 16,  3,  8, 19,\n",
      "        18, 10, 16, 16, 16, 16, 13, 13,  6, 10, 16,  3,  5, 16],\n",
      "       device='cuda:0'), tensor([16,  8,  4, 10, 16, 16, 16, 16, 16,  8, 16, 16, 16, 16,  9, 16,  8, 16,\n",
      "         3,  4, 15, 16, 16, 16, 16, 16, 16, 10, 16, 16, 13, 16],\n",
      "       device='cuda:0'), tensor([16, 10, 10, 16, 16,  5, 16, 16, 16,  3, 19, 16, 16, 16,  4, 16, 10, 16,\n",
      "        16, 10, 16, 10,  4, 16,  4, 10, 16, 16,  4, 16, 18, 16],\n",
      "       device='cuda:0'), tensor([16, 10, 16,  9, 16, 16, 16, 16, 16,  5,  7, 10, 13, 16, 16, 16, 16, 10,\n",
      "         9, 16, 16,  8, 16,  5,  4, 13,  4, 16, 16,  1, 16,  9],\n",
      "       device='cuda:0'), tensor([16, 16, 16,  4, 16, 16, 13, 16, 16, 13, 10, 16,  5, 16, 16,  5,  5,  2,\n",
      "         7, 16,  8,  8, 19, 16,  6, 16, 16,  5,  9, 16, 10,  4],\n",
      "       device='cuda:0'), tensor([10, 16, 10, 10,  4, 16, 16, 16, 10,  8,  5, 16, 10,  9,  9, 16, 16,  9,\n",
      "        10,  6,  8, 16, 16,  2,  2, 16, 16, 10,  8,  8,  8, 16],\n",
      "       device='cuda:0'), tensor([ 9, 16, 16,  9, 19, 10,  5, 10, 16,  2, 13, 16,  5,  2, 17,  8, 16,  4,\n",
      "         9,  9,  2,  2, 16, 16, 10, 10, 16,  1,  7, 16,  9,  8],\n",
      "       device='cuda:0'), tensor([10, 11, 16,  2, 16, 16,  4, 16,  9,  5,  4, 16,  9, 16, 16, 10, 10,  4,\n",
      "        16,  6,  5, 16, 16,  1, 16,  4, 16,  0,  4,  8, 16,  8],\n",
      "       device='cuda:0'), tensor([10, 11,  4, 16, 16, 10,  2, 10,  2, 10,  4,  8, 16, 16,  5, 16, 16, 16,\n",
      "        11, 10, 16, 16, 16,  8, 16,  4, 16, 10, 19, 16, 10,  5],\n",
      "       device='cuda:0'), tensor([ 4, 10, 16,  2, 10, 10,  8, 10, 16,  5, 16, 16,  2, 16, 16, 16,  6,  3,\n",
      "        10, 16,  7,  6, 10, 16, 16, 16, 16, 13, 16,  9,  4, 16],\n",
      "       device='cuda:0'), tensor([16, 16,  4, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 10, 16,  8,\n",
      "         6, 10, 16, 16, 10,  8,  3, 16, 16, 10, 16,  3,  3, 16],\n",
      "       device='cuda:0'), tensor([ 4, 10, 16, 16, 16, 10,  4, 16,  8, 16, 10, 16,  4,  4,  8, 16,  8, 16,\n",
      "        16, 16, 10, 16, 16,  4,  5, 16,  2,  9, 11, 16, 15,  9],\n",
      "       device='cuda:0'), tensor([ 2,  8,  8, 16,  8,  6,  2,  3,  0, 16, 18,  4,  2,  2, 13,  8, 16,  4,\n",
      "        10, 19,  3,  2,  5, 16, 10,  5,  1, 10, 18,  4,  5, 16],\n",
      "       device='cuda:0'), tensor([ 0, 10,  9, 18,  4,  2,  2,  8,  4,  5,  4,  2,  8,  4,  8, 10, 13, 16,\n",
      "         8,  8,  5, 13,  8,  8,  2, 19,  8,  8,  2, 13,  5, 19],\n",
      "       device='cuda:0'), tensor([ 5, 16,  8,  5, 16,  3,  8,  2, 10, 18,  4, 16,  9,  8,  4,  8, 16, 19,\n",
      "         2,  5,  8, 14,  9, 16, 16,  4, 19, 10, 18,  5, 16,  4],\n",
      "       device='cuda:0'), tensor([16, 13,  8,  5, 19,  2, 16, 16,  2,  0, 10,  8, 16, 16,  9, 16,  4,  2,\n",
      "         8, 10, 16, 16,  2,  9,  2,  8,  4,  9,  8,  5,  2, 16],\n",
      "       device='cuda:0'), tensor([16, 19,  5,  2, 16, 16, 10, 16, 10, 19, 19, 10,  4,  4, 16,  4, 16, 18,\n",
      "         8, 18,  2, 19,  0, 16, 15, 16, 16, 10,  8, 19, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  5,  8, 16, 16, 16, 13,  8, 16, 16, 16, 10, 16, 16,  7, 16, 10, 16,\n",
      "        16, 16,  6,  4,  4, 16,  5, 16,  6, 16, 16, 16,  5,  4],\n",
      "       device='cuda:0'), tensor([16, 10,  0, 10, 16, 10,  4, 13, 19,  4, 16, 16, 13, 16,  0, 16, 10, 16,\n",
      "         2, 16,  8, 16,  5,  3,  5,  4, 16, 16, 10,  9,  8,  2],\n",
      "       device='cuda:0'), tensor([ 8, 16, 16, 16, 16,  2, 10, 16, 10,  5,  8, 10, 16, 16, 13, 16,  8, 16,\n",
      "         8, 13,  5, 13,  9,  5, 10, 17,  9, 16, 16, 13,  4, 16],\n",
      "       device='cuda:0'), tensor([16,  2, 16, 16,  4,  9, 11,  8, 10,  4, 16, 16, 16,  4, 19, 16,  8,  9,\n",
      "         5, 10,  8, 16, 10, 16, 16, 16, 16, 16, 18, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  2, 13, 16,  8,  4,  5, 16, 13, 16, 10,  1,  8,  4, 16,  6, 13, 16,\n",
      "         8, 16, 19,  5, 19, 16, 16,  0, 16,  1, 16, 19,  2, 16],\n",
      "       device='cuda:0'), tensor([19, 16, 13, 16,  8, 16, 11, 10, 19, 18,  8, 19,  8, 16, 10, 16,  4, 16,\n",
      "        16,  4,  4, 19, 16, 16, 16, 16,  9,  2, 16, 10,  9, 19],\n",
      "       device='cuda:0'), tensor([ 2, 16, 16,  5,  8,  4, 16, 16,  8, 16, 11,  8, 16, 19, 16,  5,  8,  8,\n",
      "         8,  9, 10,  8,  7,  9,  8, 16, 11,  9, 10, 16,  5, 10],\n",
      "       device='cuda:0'), tensor([10,  5, 16,  8, 11, 16, 10,  7,  8, 16,  8, 16, 16, 16, 16, 13, 16, 10,\n",
      "        16, 16,  2,  5,  8,  6, 16,  8, 17,  2,  2, 16,  2,  3],\n",
      "       device='cuda:0'), tensor([ 9, 16,  4,  5,  5,  5,  4, 10, 16,  9, 16, 10, 16,  5, 16, 16,  8, 15,\n",
      "        16,  4,  5,  8, 16, 10, 10, 16, 16,  8,  5, 16, 10, 16],\n",
      "       device='cuda:0'), tensor([16,  8,  9, 13,  5,  2,  8,  5,  9, 16, 10, 19,  6,  9, 16,  4,  4,  8,\n",
      "        16, 16, 16,  6,  9, 13,  4, 16, 11, 10, 10, 16,  4, 16],\n",
      "       device='cuda:0'), tensor([16,  3, 16,  4, 19, 10, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16,  4,  4,\n",
      "        16, 16, 13,  4, 10,  8, 16, 16,  2,  5, 11, 16, 10, 18],\n",
      "       device='cuda:0'), tensor([ 4,  8, 16, 16, 16, 16, 16, 16, 16,  4, 16, 16, 10, 16, 16, 10,  8,  2,\n",
      "        16, 16, 16,  5, 16, 16, 16, 10,  3, 16, 16, 16, 11, 16],\n",
      "       device='cuda:0'), tensor([16,  5,  3,  9, 16, 16,  2,  4, 10, 16,  8, 16,  5, 16, 10, 16, 16, 16,\n",
      "        16,  3, 16, 16, 16, 16,  4,  8,  5,  8,  4, 10, 10, 13],\n",
      "       device='cuda:0'), tensor([ 5, 18, 19, 19,  9,  9,  8,  9, 13, 18, 10,  2,  5, 19,  8,  5, 19,  5,\n",
      "         4,  4,  9,  4,  2, 13, 10,  5,  1, 16, 10, 19, 16,  4],\n",
      "       device='cuda:0'), tensor([ 2, 10,  4, 10, 16,  9,  5,  8,  7,  2,  3, 16, 18, 13,  9, 16, 16,  4,\n",
      "         8,  4, 13, 16,  4,  1, 16,  2, 10, 18,  8,  4, 16,  6],\n",
      "       device='cuda:0'), tensor([16,  0, 16,  2, 10,  8, 18, 16, 16,  5,  8,  8, 16,  2,  8, 16,  8, 10,\n",
      "        16, 10,  2,  2,  8,  8,  5,  4, 10,  8,  9,  2, 16,  5],\n",
      "       device='cuda:0'), tensor([ 2, 11, 16,  6, 16,  4, 13, 10, 10,  2, 16,  2, 16, 16, 16, 10,  3,  2,\n",
      "        19,  4,  5, 10, 13,  1, 10, 10,  4, 10,  2,  9,  8, 16],\n",
      "       device='cuda:0'), tensor([10,  3, 16, 16,  6,  6, 19, 10,  2,  8, 11, 13, 16, 16, 16,  2, 17, 16,\n",
      "        13, 10, 16, 16, 16, 16,  8, 16, 16,  0, 10,  8,  5,  4],\n",
      "       device='cuda:0'), tensor([16, 16,  3, 19, 16,  5, 16, 16,  7, 19, 19,  0, 13, 16,  3, 16, 10, 16,\n",
      "        16, 16, 13, 19, 16, 14, 16,  4, 16, 16,  4, 10,  1, 19],\n",
      "       device='cuda:0'), tensor([ 5, 13, 16, 16,  5,  4, 10,  5, 16, 16, 16,  3, 16, 16, 16,  4,  8,  4,\n",
      "        16,  2,  4, 11, 10, 16,  8, 16, 13,  7,  8,  8,  4,  9],\n",
      "       device='cuda:0'), tensor([10, 16, 16,  8, 16,  8, 16, 16,  0, 16, 16, 16,  3, 19,  0, 16,  6, 13,\n",
      "         2, 16,  6, 10, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16,  2, 13, 16, 16,  1, 16, 19, 16, 16,  4,  1,  0,  5, 10,\n",
      "        16, 16, 16,  5,  4, 16,  8,  7, 16, 16,  8, 10, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  8,  5,  5, 16,  3, 19, 16, 16, 16, 10, 16, 16, 16, 16, 16, 10, 10,\n",
      "        16, 10, 16, 16,  5,  5, 11,  4, 16, 16, 16, 13, 13,  5],\n",
      "       device='cuda:0'), tensor([16, 16,  9, 16,  2, 16, 16, 13, 16, 16, 13,  3, 19,  4, 16,  8, 16, 16,\n",
      "        15,  4, 16, 16, 16,  4,  4,  3, 16,  2,  5, 16, 16,  5],\n",
      "       device='cuda:0'), tensor([16,  1, 16,  9, 16, 16, 18, 16,  5,  2,  6, 16,  8, 16, 16,  4, 16, 16,\n",
      "        16, 16, 19,  4, 16, 16,  9, 10, 16,  5, 16, 16,  4, 13],\n",
      "       device='cuda:0'), tensor([ 8, 13, 16, 19,  3, 13, 16,  4,  4,  4,  4, 13,  9,  8,  5, 16, 16,  4,\n",
      "         9,  2, 16, 16, 16, 10, 10,  5, 16,  5,  8, 16, 10,  5],\n",
      "       device='cuda:0'), tensor([16, 16, 10, 10, 10,  9, 13,  8, 16,  5, 13, 16, 16, 19,  3, 16, 16,  8,\n",
      "         9, 10,  9,  2,  2, 10, 16,  0, 16, 16, 14, 11,  3, 16],\n",
      "       device='cuda:0'), tensor([ 5,  5, 16,  5,  8, 10, 16,  2, 16, 16,  8, 16,  4, 19,  7,  8, 10, 16,\n",
      "        10, 16, 16,  2,  5,  5, 16, 16, 16, 10, 10, 19,  4, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 13, 13, 16, 13, 16, 10,  5,  9, 16, 10, 10, 16, 11,  8,  9,\n",
      "         5,  6, 16, 16,  8,  9,  2,  8,  5,  8,  8, 16, 16,  1],\n",
      "       device='cuda:0'), tensor([ 8, 16, 10, 16,  9,  8, 16, 10, 16,  8,  3,  4, 10,  8, 16, 10,  3,  4,\n",
      "        19, 13,  4,  8, 10, 16,  6, 16,  4, 16, 10,  5, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  5, 16, 16, 16, 10, 16, 16,  8,  8, 16, 16,  5,  8, 16,  9,  8,  4,\n",
      "        16, 16,  4, 10, 16, 16, 10, 16, 16, 16, 10, 16,  4, 16],\n",
      "       device='cuda:0'), tensor([16, 16,  5, 16, 16, 16,  3,  4,  5, 16, 16, 16,  2, 10,  4, 10, 16, 10,\n",
      "        16,  3, 16, 18, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([13, 16, 16, 16, 10, 16, 16, 16, 16,  2, 16,  5, 16,  4, 16, 16,  5,  3,\n",
      "        16,  8, 16, 13, 16,  4, 16, 16, 16, 10, 16,  3, 10, 16],\n",
      "       device='cuda:0'), tensor([ 3, 16,  8,  8, 16, 19,  8,  0,  4,  2,  2,  2, 10, 18,  4, 10, 10,  9,\n",
      "        19,  2, 10, 10, 10,  3,  4, 10,  5,  5,  2,  5,  9, 10],\n",
      "       device='cuda:0'), tensor([ 9,  9, 18,  9, 16,  8, 16,  8, 19,  2,  3,  6, 16, 19,  4, 16,  2, 16,\n",
      "         7, 19,  8,  2,  9,  5,  4,  8,  8,  3,  8,  8, 16,  8],\n",
      "       device='cuda:0'), tensor([ 8,  4, 16,  8, 10, 13,  9, 16,  2,  4,  5,  2, 16,  8,  4, 10, 16,  4,\n",
      "        16,  2,  2, 10, 10, 16, 10,  8,  8,  8,  5,  5,  8,  5],\n",
      "       device='cuda:0'), tensor([ 9, 13,  4,  8, 10, 10, 11,  8,  8,  2, 16,  4, 13, 16, 16,  2, 16,  8,\n",
      "         3,  5,  6, 19,  6,  4, 16,  5,  5,  5, 10,  2,  3, 16],\n",
      "       device='cuda:0'), tensor([10,  4, 16, 18,  3, 16, 16,  8,  4,  0, 16, 16,  8, 11,  4,  2,  8,  4,\n",
      "         8, 10, 16, 16, 16, 16, 19, 16, 16,  5, 10, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 19,  4, 16, 10, 16, 19,  5, 10,  9, 16,  4, 16, 16, 10, 16,  3,\n",
      "         4,  4, 16, 16,  2,  5, 16,  8, 16, 16, 16, 16, 10, 16],\n",
      "       device='cuda:0'), tensor([13, 19, 19, 16, 19,  2, 16,  8,  4, 19, 16, 13, 10,  0, 13, 16, 16, 16,\n",
      "        16, 10,  0, 16, 16, 10, 13, 15, 16, 16, 10,  8, 16, 16],\n",
      "       device='cuda:0'), tensor([ 4,  4,  6, 16, 16, 16,  9,  4,  5,  8,  2, 16, 16, 16, 16,  8, 16,  4,\n",
      "        16, 16, 10,  9, 10,  4, 10,  9, 18, 16, 16, 16,  8,  5],\n",
      "       device='cuda:0'), tensor([ 1, 16, 19, 16, 16,  4,  3, 16, 16, 16, 16, 16,  4,  5, 10,  4, 13, 16,\n",
      "        16,  8,  8, 16, 16,  3,  8, 16,  8, 10,  1, 19, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  4, 16, 16,  4,  0, 16,  4,  8, 16,  4, 16, 10,  8, 10, 10, 10, 16,\n",
      "        16,  9, 16, 16,  8, 13, 16, 13, 13, 16, 19, 19, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16,  7,  9, 19, 16, 16, 16, 16,  2,  5,  9, 16,  3, 16,  8,\n",
      "         5, 16, 16, 13, 16,  4,  3,  2, 16,  8, 10, 16, 16,  4],\n",
      "       device='cuda:0'), tensor([ 8,  4, 16, 18, 10,  8,  6, 10, 14,  3, 16, 19, 19, 10,  8, 16, 13,  8,\n",
      "         2, 16,  8, 16,  6, 16,  4, 16, 10, 16,  8,  5, 16,  8],\n",
      "       device='cuda:0'), tensor([ 9, 16, 14, 13,  8, 16,  9, 19, 16, 16, 16, 16, 13,  4, 16, 18,  4, 13,\n",
      "         4,  8, 16,  6, 16, 10, 19, 10, 16,  8,  3,  8, 10, 16],\n",
      "       device='cuda:0'), tensor([ 8,  8,  3, 16,  3,  7, 13,  9,  8, 19, 16,  6, 10, 19, 16, 16, 16,  8,\n",
      "        16,  2,  5,  9, 10,  5, 16,  4,  5, 10,  8, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 19, 16, 16, 16, 16, 13,  7,  9,  5,  9, 13, 16, 13, 10, 16, 16,  4,\n",
      "         9,  2, 16,  8, 16,  3,  0, 10,  2, 16, 16, 16, 16,  2],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16, 10,  4, 10, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16,  2, 16,  6, 16, 16,  9,  3, 10,  4, 16, 16,  6, 16],\n",
      "       device='cuda:0'), tensor([13, 16, 19, 16, 16, 10,  0, 16,  5,  2,  3,  4, 13, 10, 16, 16,  7, 16,\n",
      "        16,  3, 16,  2, 10, 16,  3, 16, 10, 16, 18,  6,  4,  2],\n",
      "       device='cuda:0'), tensor([16,  3, 16, 16, 16, 16, 16,  5, 16, 10,  4, 16, 16, 16,  5, 16,  9,  5,\n",
      "         5,  5,  3,  5, 16, 16, 16, 10,  7, 10, 16, 16,  8, 10],\n",
      "       device='cuda:0'), tensor([ 8,  0,  8, 13,  5,  5,  4,  8, 10,  2,  5, 16, 10, 13, 10,  8,  5, 16,\n",
      "         5,  9, 16,  9, 16, 19, 10, 16, 10, 16,  8, 10,  5, 10],\n",
      "       device='cuda:0'), tensor([ 5,  9, 10,  0, 11,  2, 16, 10, 18,  8,  2,  2, 19,  2,  7, 16,  8,  9,\n",
      "         8,  5, 16,  2, 18,  8,  2,  2,  2, 13,  5, 10, 13, 10],\n",
      "       device='cuda:0'), tensor([ 8, 10,  4,  9,  8, 16, 16,  2,  0, 10, 10,  9,  2,  2,  8,  9,  2, 16,\n",
      "        19,  2,  2, 18, 19,  9,  9,  4,  0, 10, 16,  2, 10,  8],\n",
      "       device='cuda:0'), tensor([16,  8, 16, 13, 13, 16, 16, 16, 16, 16, 16,  5,  8,  2,  4,  2,  8, 10,\n",
      "        13,  3, 16,  5,  4, 15,  8, 18, 10, 10, 16,  4,  5, 19],\n",
      "       device='cuda:0'), tensor([13, 15, 16, 16, 16,  4,  4, 19, 16, 16,  4,  2,  8, 19,  3,  8, 16, 16,\n",
      "         9, 10,  4, 10, 16, 16,  8, 13, 10, 16, 19,  2, 16, 19],\n",
      "       device='cuda:0'), tensor([11,  4, 16,  9,  5, 16,  7, 16, 16,  5,  8,  6, 16, 15,  6, 19, 16, 16,\n",
      "        16,  8, 16, 16,  4, 16, 19, 10, 16,  8,  5,  4, 16,  4],\n",
      "       device='cuda:0'), tensor([ 8,  2, 19, 11,  2,  4, 16,  6,  2, 16, 16, 16, 16, 16, 16, 16, 13, 16,\n",
      "         4, 16,  7,  7,  9, 16,  4, 16, 16, 10, 16, 17,  8, 10],\n",
      "       device='cuda:0'), tensor([16, 16,  4, 16,  4, 13, 16, 16,  8,  6, 16, 16,  8, 19, 16, 16, 16, 10,\n",
      "        16, 13, 10,  8, 16,  5, 16, 16, 16, 16,  8, 16, 16,  8],\n",
      "       device='cuda:0'), tensor([16,  6,  5, 10,  8, 13, 16, 16, 16,  4, 10, 13, 16, 16, 13,  4, 17, 11,\n",
      "        18,  2,  5,  8, 16, 16, 10,  4, 13, 10, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 4, 16,  6, 16, 16, 10, 16,  6, 16,  4, 16, 10, 16, 16,  8,  3, 11, 13,\n",
      "         4, 16,  9, 16,  8, 18, 16,  2,  5,  4,  4,  5,  5,  3],\n",
      "       device='cuda:0'), tensor([16,  6,  8, 10, 13, 10, 16, 10, 10, 19, 16, 16, 16,  5, 13, 16,  3, 16,\n",
      "        16, 16, 16, 16, 16, 13, 16, 16, 14,  2, 16, 13, 16,  4],\n",
      "       device='cuda:0'), tensor([16, 16,  4, 13,  2, 10, 16,  7, 16,  2,  8,  2, 18,  3, 16, 16, 16,  3,\n",
      "         2, 10,  2,  6, 11, 16, 16,  8,  4, 16, 16, 16,  9, 16],\n",
      "       device='cuda:0'), tensor([ 4,  2, 11, 10, 19,  6, 13,  3, 10, 10,  2,  2, 16,  9, 16,  6,  9,  8,\n",
      "        16, 10,  6,  4,  8,  8,  9,  2,  9,  3,  9,  8, 16, 16],\n",
      "       device='cuda:0'), tensor([10,  3, 10, 16,  8,  8, 11, 16, 10,  5,  6,  5, 16, 16, 16,  8, 10,  2,\n",
      "         2, 16,  4, 17,  8, 16,  5, 16, 10, 16,  2, 16,  2, 18],\n",
      "       device='cuda:0'), tensor([19,  5, 16, 14,  9, 16, 10, 19, 16, 16,  9, 16,  5, 16, 16,  0, 16,  8,\n",
      "         5, 10, 16, 16, 16,  3, 16,  4,  5, 19, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 4, 16, 16,  5, 16, 16, 10, 16, 17, 10, 16,  9, 16,  2, 10, 16,  8,  8,\n",
      "         4,  2, 10,  4,  8,  4, 10, 16,  5, 10,  4, 16,  4, 16],\n",
      "       device='cuda:0'), tensor([ 5,  8,  8, 16,  8, 16, 10, 16, 16, 16, 13, 10, 10, 16, 16,  4, 16, 13,\n",
      "        16,  4,  4,  4, 16, 16, 16, 16, 10, 16, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 6,  5, 16, 16,  4,  6,  8, 16,  3, 16,  3,  3, 10,  6, 14, 16, 16, 16,\n",
      "         8, 17,  2,  3, 16, 16, 16, 10,  5,  4, 16,  4, 16, 13],\n",
      "       device='cuda:0'), tensor([ 9, 16, 10, 16, 16, 13, 16, 16,  8, 10, 10,  2, 10, 10,  8, 14,  8,  9,\n",
      "        16, 10,  2,  6,  9,  4,  4,  2,  2,  4, 16,  5,  8,  8],\n",
      "       device='cuda:0'), tensor([10, 10, 15, 10, 10,  8,  4, 10, 10, 10, 16, 10,  8, 10,  5, 10,  5, 13,\n",
      "        10,  8,  9,  8,  5, 10,  9,  9,  1, 19,  9,  2,  2, 16],\n",
      "       device='cuda:0'), tensor([ 8,  0, 13,  2, 17,  2,  4, 16,  4,  8, 19, 16, 19, 10,  4, 10,  8, 10,\n",
      "         3,  2,  8,  2,  2,  4, 13, 16,  5, 13, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 8,  8,  8,  9,  8,  2, 19, 19, 16, 16,  4, 19, 16,  2,  9,  2,  5, 16,\n",
      "         2, 16,  5, 16,  2,  8, 10,  3,  3, 16, 18, 13,  4, 10],\n",
      "       device='cuda:0'), tensor([ 4,  3, 13,  9, 16, 16,  0,  5, 10,  1, 16,  2, 16, 16,  8,  8, 16, 16,\n",
      "        16, 10,  2, 16, 19,  4, 16, 16, 16, 16,  0,  8, 16,  6],\n",
      "       device='cuda:0'), tensor([ 8, 10, 10, 10, 16, 16,  3, 13,  8, 19, 16, 10,  6, 16, 13, 16,  4, 16,\n",
      "        16,  3, 10, 10,  8, 16, 16,  9, 16,  9,  4,  2, 13,  8],\n",
      "       device='cuda:0'), tensor([ 4, 10, 16, 10, 16, 16,  4,  8, 10,  9, 16, 16, 16,  1,  3, 16,  2, 16,\n",
      "         3,  2, 10, 16, 16, 13, 10, 16, 16, 16,  5, 13, 11, 16],\n",
      "       device='cuda:0'), tensor([16, 10,  4, 16, 10, 11,  8, 16, 10, 16, 16, 16, 15, 16, 16, 16, 16, 16,\n",
      "        10,  4,  8,  4,  8, 10,  2, 16, 16,  5, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([19,  8, 16, 19,  8, 16, 10, 16,  3, 10,  3, 16,  8, 16, 16, 16, 16, 19,\n",
      "        14, 16, 19, 16, 16, 16,  4, 16,  1, 16, 16,  5, 16,  5],\n",
      "       device='cuda:0'), tensor([19, 10,  5, 16, 16, 16, 16, 16,  6, 11,  8,  4, 16,  4, 16, 16, 16, 10,\n",
      "         5, 16,  2,  8, 10,  6, 10, 16, 16, 16, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([19,  8, 18,  5, 16, 19,  3,  9,  4, 16,  4, 10,  4, 13, 16, 16,  4,  4,\n",
      "        16, 16,  8, 10,  5, 16, 16,  8, 16, 10,  5,  5, 10, 10],\n",
      "       device='cuda:0'), tensor([ 4, 16, 16,  5,  9, 16, 16,  8, 16,  9,  5,  5, 19,  6,  4, 10,  8, 10,\n",
      "        16,  6, 16,  5,  5, 19,  2,  8,  2,  6,  8,  3, 10,  2],\n",
      "       device='cuda:0'), tensor([ 9,  5, 10, 10, 16,  5,  0, 16, 16, 13,  4,  2,  2, 16,  4, 16,  9, 10,\n",
      "         8,  4, 16,  4, 16,  9, 16, 16, 16, 10, 16, 16,  9, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16,  4,  8, 10, 18, 16, 16, 16,  5,  8, 16,  2,  8, 16,  8,  2,\n",
      "        10,  1, 16,  5, 19, 16,  8,  8,  5,  2, 16, 16,  3,  2],\n",
      "       device='cuda:0'), tensor([16,  3,  5,  6, 10, 10, 10, 16,  5, 19,  5,  5, 16, 10, 19,  8,  2,  5,\n",
      "        10, 16,  3,  5, 10, 19, 16, 16,  2, 16, 16,  8,  5, 16],\n",
      "       device='cuda:0'), tensor([ 6,  7,  4, 10,  4,  6, 16, 10, 16,  4,  3, 16, 15,  4,  2, 16, 19, 16,\n",
      "        16, 16,  4, 16, 16,  8,  8,  8, 19,  7, 16,  4, 16, 15],\n",
      "       device='cuda:0'), tensor([19,  8,  4,  5,  4, 16,  5,  4, 16, 16,  8, 16, 13, 16,  5, 10, 16,  8,\n",
      "        16, 16, 16, 10, 16, 10, 16, 16, 10,  5,  9,  2,  2, 16],\n",
      "       device='cuda:0'), tensor([ 2, 16, 16, 16, 10,  8,  4, 11,  4, 10, 16,  2, 16, 10,  9,  9, 16, 16,\n",
      "        16, 14, 16, 16,  8, 16,  5, 13, 19, 13,  5,  4, 10,  8],\n",
      "       device='cuda:0'), tensor([ 3, 10,  8, 10,  9, 15,  8,  2, 13, 14, 16, 11, 10,  3,  4, 16,  1,  2,\n",
      "         2,  4, 10,  2,  4, 10, 10,  9, 10,  1, 16,  8,  3,  6],\n",
      "       device='cuda:0'), tensor([ 8, 10,  9,  2,  7, 16,  9,  4, 16, 13,  8,  8,  2, 19,  4,  9,  1,  8,\n",
      "        10,  2, 10, 19,  5,  2, 18, 16, 16, 19,  2,  2,  5, 10],\n",
      "       device='cuda:0'), tensor([ 2,  2, 10,  5,  5, 19, 10,  4,  2,  4,  2,  8, 10, 10,  4, 16,  2, 16,\n",
      "         8, 16, 16, 16, 19,  8, 16,  2,  5,  5, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 9,  5,  8, 13,  5,  8,  4,  4, 16, 10, 10,  9, 10, 19,  2,  4,  9,  9,\n",
      "        18, 16, 16, 10,  4,  3,  5,  0, 16,  2,  5,  8,  4,  9],\n",
      "       device='cuda:0'), tensor([16, 10, 19, 16, 10,  3,  4,  3, 19, 10, 13,  8, 16,  3,  8,  5, 10,  9,\n",
      "         4, 16,  4, 13, 10, 16, 16, 18, 16,  3, 16, 16, 16,  8],\n",
      "       device='cuda:0'), tensor([ 8, 19, 16,  4,  3, 16, 16,  2,  2,  8, 16, 16, 16, 16, 16, 16,  7,  6,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 10, 16, 16, 16, 10,  8],\n",
      "       device='cuda:0'), tensor([ 8,  8,  8,  5, 19, 16,  2, 10, 16, 16, 16,  8,  5, 10, 16, 16, 16,  4,\n",
      "         5,  4, 16,  8, 16,  4,  3, 16, 16, 17, 16,  2, 16, 19],\n",
      "       device='cuda:0'), tensor([15, 16, 10,  6,  5,  4,  4, 19, 16, 19,  3, 16, 16, 13, 10, 18,  2, 19,\n",
      "        13, 13,  8, 16, 16, 16, 16, 16, 16,  4, 10,  5,  8,  3],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16, 13,  3, 10,  8, 10, 16, 16, 16, 18, 16, 16, 16, 19, 16,\n",
      "         9,  9, 16, 16,  5,  4,  8,  8, 16, 16, 16, 16,  2, 10],\n",
      "       device='cuda:0'), tensor([ 2,  2, 16, 16, 16,  8,  6, 16, 16, 10, 13, 16,  4, 16, 16, 16, 16,  5,\n",
      "        16, 16, 16,  4,  8, 16,  0, 16,  4,  0, 16, 10,  2,  5],\n",
      "       device='cuda:0'), tensor([16,  4, 19,  5, 16, 16,  4,  9, 16,  9,  5,  8, 16,  2, 10,  5, 10,  9,\n",
      "        13,  8,  4, 10,  8,  6, 16, 16,  9,  5,  4,  0, 10, 16],\n",
      "       device='cuda:0'), tensor([16,  8,  3, 16,  2,  8, 16, 16,  8,  3,  2, 16, 19, 16,  5, 10, 16,  8,\n",
      "        16,  0, 16,  5,  9, 16, 16, 16, 16, 16,  6,  6,  8, 16],\n",
      "       device='cuda:0'), tensor([16, 19,  8, 16, 19, 16,  9, 10,  4, 19,  5, 16,  8, 19,  5, 10, 16,  9,\n",
      "         6,  9,  4,  2,  9,  0, 16, 16, 19, 16,  4, 10, 16,  8],\n",
      "       device='cuda:0'), tensor([ 8, 10,  8, 16,  8,  9,  5, 18, 10, 16, 11, 16,  8, 13,  2, 10, 10,  5,\n",
      "        16, 16, 15,  3, 18, 16, 16, 10, 16,  9,  4, 16,  8,  9],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 18, 16,  3,  4, 16,  6, 16, 16, 16, 19, 16,  9,  4, 16,  5,\n",
      "         9, 16, 11, 16,  4, 10, 16,  2,  5, 15, 10, 10,  8, 16],\n",
      "       device='cuda:0'), tensor([16, 10,  3,  8, 16,  4, 16,  3,  2, 16, 16, 16, 16, 13, 17, 16,  9, 16,\n",
      "        16, 16, 10, 16, 10, 16, 16,  6, 16, 16, 16, 10, 11, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16,  4, 16, 16,  4, 16, 16, 19,  9, 16, 16, 19,  7,  8,  2, 10,\n",
      "         8, 10, 10, 10, 16,  5,  8,  5,  4,  0,  6,  2, 16,  2],\n",
      "       device='cuda:0'), tensor([ 5, 16, 10, 19, 13,  5,  2, 10,  5, 10,  4, 16,  5,  9,  3,  2, 18,  4,\n",
      "         4,  2, 16,  8, 16, 19,  8,  8, 10,  8, 19, 18,  7,  5],\n",
      "       device='cuda:0'), tensor([ 4, 10,  8,  2,  9,  8,  8, 10, 10, 16,  5, 16,  2, 16, 13, 16,  3, 16,\n",
      "        16, 10, 19, 10, 10,  8,  2,  2,  6,  2, 10, 10,  9,  9],\n",
      "       device='cuda:0'), tensor([ 5, 10, 18, 16, 16, 10, 16, 16,  2, 16,  9,  8,  8,  9, 16,  3,  5, 16,\n",
      "         9, 18, 16, 16, 16,  9,  9, 16, 19,  9, 11, 16, 19,  8],\n",
      "       device='cuda:0'), tensor([16, 10, 16, 10, 16,  2,  3, 19, 16, 10,  8, 16, 16, 16, 10, 13, 16, 10,\n",
      "        10, 10, 16, 19, 16, 13, 16, 16,  8,  6, 16, 10, 11, 16],\n",
      "       device='cuda:0'), tensor([16, 10,  9, 16, 16,  0, 16, 18,  2, 16, 16,  4, 16,  6,  4, 18, 19,  8,\n",
      "        16, 16,  8,  8,  5,  4, 16, 17,  7,  5, 10, 10, 10, 10],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16,  5,  8,  9, 16,  4,  5, 16, 15,  4,  2,  2,  6, 10, 16,\n",
      "         4,  5, 16,  2, 10,  5, 16, 16,  9, 19, 16, 16, 10,  3],\n",
      "       device='cuda:0'), tensor([19, 16, 16, 16, 16, 10, 16, 10, 10, 16,  4, 16, 18, 10, 16, 10,  6, 16,\n",
      "        16, 19,  4, 16, 16, 10,  6, 16,  4,  8, 16, 16,  2, 16],\n",
      "       device='cuda:0'), tensor([16,  6, 16, 10,  4, 10, 19, 16, 16,  8,  4, 13,  6,  4, 16, 16, 16, 16,\n",
      "        16, 16, 16, 19,  4,  8, 16, 16,  4, 16, 10,  4, 16,  8],\n",
      "       device='cuda:0'), tensor([ 4, 10, 13,  4, 16, 16,  9, 16, 11, 19, 16, 16, 18,  8, 16, 16, 16, 16,\n",
      "        13,  5, 16, 10,  3, 16,  4, 16, 16,  2, 16,  8, 10, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 13, 16, 16, 16,  4, 16, 19,  5, 16,  5, 16, 16, 16, 18,  5,  9,\n",
      "        16,  4,  9,  8, 13, 16,  5,  4,  8,  8,  4,  9, 16,  4],\n",
      "       device='cuda:0'), tensor([ 5,  4, 16,  8,  8, 16,  5, 10, 16, 19, 10, 19, 10,  0,  4, 10, 16,  8,\n",
      "        16, 16, 16,  5,  8,  4,  9, 16, 16, 16, 16, 16,  8,  2],\n",
      "       device='cuda:0'), tensor([16,  1, 19, 16, 16, 10,  6,  4, 10, 16,  8, 16, 10, 10, 16, 10,  9, 16,\n",
      "        10, 16,  8, 16, 16, 16,  3,  2, 16,  8,  8,  3, 16,  2],\n",
      "       device='cuda:0'), tensor([16,  8, 16,  4, 16, 16, 16,  8, 16,  8,  8, 10, 10,  7,  2,  4,  8, 18,\n",
      "         9,  8,  4,  4, 19,  8, 16, 16, 10,  8, 10,  4,  1,  5],\n",
      "       device='cuda:0'), tensor([16,  9,  4, 10, 19,  8,  8, 16,  4, 16, 18,  6,  6, 16, 16,  9, 13,  6,\n",
      "         4, 10, 10, 16, 16,  2, 15,  2, 10, 16, 16, 10, 16,  5],\n",
      "       device='cuda:0'), tensor([ 2,  3,  8,  3,  5, 13, 16,  5,  5,  4,  8, 16, 16, 10, 16,  4, 16,  4,\n",
      "        16, 10, 16,  4, 16, 10, 16,  5, 16,  4, 16,  8, 16,  4],\n",
      "       device='cuda:0'), tensor([16, 13, 11,  5, 16, 10, 16, 10,  3, 16, 16, 16,  4, 16, 16, 16,  8,  2,\n",
      "         8, 16, 18, 16, 10, 16, 16, 16, 16, 16,  8,  5, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  6, 16, 16, 13, 10, 16,  8, 16,  5,  2,  5, 16, 16,  8, 16, 16,  1,\n",
      "        16, 13, 16, 16,  0, 10,  7, 13, 16,  8,  4,  2, 19, 16],\n",
      "       device='cuda:0'), tensor([ 4,  8, 10, 10, 19, 16, 11,  2, 16,  0,  4,  9,  3, 16,  2, 14,  4,  2,\n",
      "        13,  5, 10,  5, 16,  8,  8, 16,  9,  4,  2,  9, 16, 19],\n",
      "       device='cuda:0'), tensor([10,  8, 10,  8,  2, 16,  2,  8,  2,  8, 19,  8, 10, 13,  0,  2, 19,  8,\n",
      "        10,  8,  8, 18,  9,  8,  9,  2,  3,  2,  5, 10,  2, 10],\n",
      "       device='cuda:0'), tensor([ 2, 16,  8,  2, 18, 16,  9,  4,  8,  2, 16, 13,  5, 16, 16, 16, 13, 16,\n",
      "         2,  2,  5, 16, 10,  9,  5,  5,  2, 16,  2, 10, 16,  8],\n",
      "       device='cuda:0'), tensor([18, 16, 10, 16, 19, 16, 15, 19, 16, 16, 16,  5, 10, 16, 16,  8, 16, 13,\n",
      "         3, 19,  2, 16,  5,  8,  8, 16, 16,  4,  8,  4, 19,  8],\n",
      "       device='cuda:0'), tensor([16,  7, 10, 16, 19, 16, 13, 16, 10, 10, 16,  4, 16,  3, 16,  4,  2, 13,\n",
      "        16, 19,  2, 16, 16, 16, 10,  8, 19,  1,  9,  8, 16, 10],\n",
      "       device='cuda:0'), tensor([16,  8,  8,  0, 16, 16,  8,  1,  4, 16,  5,  4,  2, 16, 10, 16, 16, 16,\n",
      "         9, 16,  8, 19, 16,  6, 16, 19, 16, 19, 16, 16,  1,  4],\n",
      "       device='cuda:0'), tensor([ 2, 19, 16, 11, 16, 16, 16, 16,  8,  5, 16, 14, 16,  4, 16, 16, 16,  0,\n",
      "         5, 10, 16,  8,  4, 19,  8,  4,  4, 16, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 4,  8,  6, 16,  9, 16,  8,  5, 16, 18,  4, 16,  4, 16, 16, 16, 16,  1,\n",
      "        16,  3, 13, 13,  2,  5,  6,  5,  8, 16, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 10,  4, 19, 19, 16,  8, 16, 16, 19, 16,  4, 10, 16,  8, 17, 16,\n",
      "        16, 10, 16, 16,  8,  4, 16, 16, 16, 16, 16,  4, 10, 16],\n",
      "       device='cuda:0'), tensor([ 6, 16, 16,  3, 16, 10,  3, 19, 16, 16, 17, 16, 16, 18, 16, 19, 16,  3,\n",
      "        13,  8,  4, 16,  5, 16, 16, 16,  0,  4, 10,  6, 10, 16],\n",
      "       device='cuda:0'), tensor([ 5, 16,  8, 16,  2, 10, 16, 16,  4,  5,  4,  5, 10, 16, 16,  5, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16,  0, 16,  4, 10,  5],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 10, 16,  8, 13, 16,  9, 10,  2, 16,  2, 16,  9, 16,  8,  4,\n",
      "         9,  4, 16,  8,  8,  4, 16,  5,  4,  8,  5, 10, 16,  4],\n",
      "       device='cuda:0'), tensor([16,  4,  4,  9, 16, 10,  4, 11,  9,  4,  9, 16,  5, 10, 14, 16, 16,  0,\n",
      "        16,  5,  8,  2, 16, 10,  2, 19, 16, 10,  9, 16,  3,  9],\n",
      "       device='cuda:0'), tensor([ 8, 16,  2,  4, 13,  5,  8, 16, 10, 16,  2,  3,  2, 16, 16,  4, 10,  5,\n",
      "        16, 16,  5, 16,  2,  8,  4, 10,  3,  9,  8,  3,  4, 16],\n",
      "       device='cuda:0'), tensor([16,  6, 19,  2, 16, 16,  2, 10,  0, 18,  2, 16,  5,  4, 15,  4,  4, 16,\n",
      "         3,  8, 13, 14, 16, 10, 16,  6,  0,  3, 16,  8,  8,  5],\n",
      "       device='cuda:0'), tensor([13, 16, 16,  5, 10, 16, 16, 16,  9,  6,  6,  6,  9, 17,  8, 16, 16,  2,\n",
      "        16,  9, 16, 10,  8,  4,  4, 16, 16, 16, 10, 16, 10,  4],\n",
      "       device='cuda:0'), tensor([11,  5, 16, 16, 16,  4, 16, 16, 16, 10,  2, 16,  7,  2, 10,  9, 16, 10,\n",
      "        16, 16, 13, 16, 16, 16, 10, 16,  8,  5,  4, 16,  5, 16],\n",
      "       device='cuda:0'), tensor([19, 16, 16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16, 16, 16, 16,  8,  6,\n",
      "        16, 16, 16, 13, 18, 16, 16,  6, 16, 16,  8, 10,  6, 10],\n",
      "       device='cuda:0'), tensor([16, 16,  6, 10, 16, 10, 16, 16,  7, 16,  5, 10, 16, 10, 17,  4, 16, 10,\n",
      "         5,  2, 16, 19,  4,  4,  4, 16,  8, 10, 13, 14, 10, 16],\n",
      "       device='cuda:0'), tensor([16,  4, 19,  8, 10, 19,  2,  8,  9,  8,  9, 16,  4,  8,  9,  2,  6, 10,\n",
      "         9, 19, 10, 10, 10,  5, 10, 19, 19,  2, 14, 13, 16,  4],\n",
      "       device='cuda:0'), tensor([ 4,  2,  4, 19,  2, 19, 10,  1,  2,  8,  7,  2, 19, 16, 16,  5, 19, 16,\n",
      "         9,  8, 10,  2, 19,  2,  4,  8,  2, 10,  5, 10, 10, 10],\n",
      "       device='cuda:0'), tensor([ 5,  8,  8,  8, 16, 16, 10, 10,  2, 10, 13, 19, 18, 16,  5, 13,  8, 16,\n",
      "        10, 16, 15,  5,  9, 19,  6,  8, 10, 16,  5,  8,  8,  2],\n",
      "       device='cuda:0'), tensor([16, 19,  5,  4,  2,  4, 16, 16,  8, 10, 10, 16, 19,  5, 16, 16, 16, 11,\n",
      "        16, 10, 10, 16, 10,  2, 16, 13, 16, 16, 14, 16,  9, 16],\n",
      "       device='cuda:0'), tensor([16, 13, 10, 16, 11, 16, 16,  6, 16,  6,  3, 19,  1, 16, 16,  8,  5, 16,\n",
      "        13, 16,  5, 16, 16,  5,  2,  8, 16, 13, 10,  8,  4, 16],\n",
      "       device='cuda:0'), tensor([ 0, 16,  3, 19, 16, 10,  5,  9,  4, 16, 16, 10, 11,  5,  5, 16,  4, 10,\n",
      "         3,  2, 16,  5, 16, 16,  2, 16, 13, 16, 16, 16,  5,  5],\n",
      "       device='cuda:0'), tensor([16, 16,  8, 16, 15, 19, 16, 16, 16, 16,  4, 16, 16, 16, 16,  4, 16,  8,\n",
      "         1,  9,  5, 16, 13,  4,  5, 16,  9, 13, 16,  4, 16, 16],\n",
      "       device='cuda:0'), tensor([ 5,  2, 16, 10,  8, 10, 16,  4, 16, 16, 16, 10,  3, 13, 16, 16,  3, 19,\n",
      "         3, 16, 16,  8, 16, 16, 16, 16, 16,  2, 19, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16, 16,  8, 16, 10,  4, 16, 16, 10, 16,  8, 16, 10,  8, 16,\n",
      "        16, 16,  3, 16,  4,  5, 16,  6, 16, 19,  4, 16, 19, 16],\n",
      "       device='cuda:0'), tensor([ 5, 16, 16, 19, 16, 13, 16, 16, 11, 16, 19, 16,  8,  4, 13, 16, 16, 13,\n",
      "        16, 16, 16, 19,  8, 13, 16, 10, 10, 16, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 15,  8, 16, 19, 10,  5,  8,  8, 16,  8, 16, 16,  8,  5,  2, 16,\n",
      "        16, 10, 14, 16, 16, 10,  5, 10, 13, 19,  9,  3, 10, 10],\n",
      "       device='cuda:0'), tensor([16,  2,  2,  2, 18, 10,  5, 16, 19,  2,  8, 19,  9,  3,  9, 19,  9,  9,\n",
      "         4, 16, 16, 16,  9, 16, 16, 15,  2,  8, 10, 16,  9, 10],\n",
      "       device='cuda:0'), tensor([16, 16, 16,  3,  6, 10, 10,  4, 13, 16, 10, 16,  5,  5, 19,  5,  5, 16,\n",
      "         4,  8, 16,  2,  7, 16, 10,  8, 16,  5, 10,  5, 16, 10],\n",
      "       device='cuda:0'), tensor([ 3, 16,  9, 10,  2,  3, 16,  4,  2, 16, 16,  5, 16,  5,  2, 16,  8,  5,\n",
      "         2, 16,  5,  8, 16, 19, 14,  4,  6,  4,  6, 16, 16,  5],\n",
      "       device='cuda:0'), tensor([ 5,  4, 16, 16,  4, 16, 16, 16, 16, 10, 16,  6,  8, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16, 16],\n",
      "       device='cuda:0'), tensor([11,  4, 10,  4, 16, 16,  8, 16, 16,  3, 16, 16,  8, 16, 10, 16, 16, 16,\n",
      "         4, 16, 16,  4, 16, 10, 18, 16, 16, 16,  4, 16, 16, 10],\n",
      "       device='cuda:0'), tensor([ 3, 16, 13, 16, 16, 16, 16, 16, 16, 16,  7, 18,  7,  8, 16, 16,  9, 16,\n",
      "        19,  0,  2, 10,  2, 18,  4,  9, 10,  9,  4,  9, 10, 16],\n",
      "       device='cuda:0'), tensor([18, 10,  5,  2, 13, 13,  2, 16, 10, 16,  5, 16, 10,  9,  5,  5,  5,  4,\n",
      "        16,  9, 19,  4,  2,  2,  2,  8,  4, 16,  8, 16,  8,  2],\n",
      "       device='cuda:0'), tensor([16,  2,  2, 16,  4,  9,  0,  8,  5,  9,  2,  6, 10,  4, 16, 16,  5,  8,\n",
      "         3,  4, 13, 10,  9, 16, 16,  3, 19, 16,  8, 10, 16, 16],\n",
      "       device='cuda:0'), tensor([ 4,  6,  6, 16, 11,  2, 16, 16,  4,  5,  4,  8, 13, 16, 16, 11, 14, 16,\n",
      "        19,  5, 10, 15, 18, 10, 10,  8, 10, 10, 13, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([10, 16, 19, 16, 16, 16,  5,  2,  0,  4,  1,  8,  5, 19, 10, 16, 10, 10,\n",
      "        10, 16,  9,  3, 16,  8, 16,  0, 16, 10, 16,  5, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  8, 10,  9, 10,  8,  3, 19, 13,  9, 16, 16, 16, 10, 16, 16, 15, 16,\n",
      "        16, 16, 19,  7, 16,  8, 18, 10,  6, 10,  5, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 4,  6,  9,  6, 16, 19,  6, 16,  5,  2, 16, 16, 16,  8, 16,  5,  2,  8,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 10, 16, 13, 16,  9],\n",
      "       device='cuda:0'), tensor([10, 10,  8, 10,  4,  8, 16,  8, 16,  2, 10, 10, 16, 10,  5, 16, 19, 16,\n",
      "         2, 16, 16, 16, 16, 16, 16, 10, 16, 16, 16, 10,  3,  8],\n",
      "       device='cuda:0'), tensor([ 9, 16,  9, 10,  5, 16, 16, 16,  5, 10, 10, 16,  2, 16, 16, 11, 16, 16,\n",
      "        14, 16, 16, 16,  5, 16, 16, 16, 16, 19, 16, 19, 16,  8],\n",
      "       device='cuda:0'), tensor([19,  4, 16, 16, 16, 16, 16, 16,  8, 16,  5, 10, 16, 10, 10, 19, 16, 10,\n",
      "         3,  4, 10, 16, 19, 16, 16, 16, 19, 16, 16, 16, 19,  4],\n",
      "       device='cuda:0'), tensor([ 4, 16, 16, 18, 13,  2, 16, 19, 16, 16,  2,  4,  2,  3, 16, 13, 10, 10,\n",
      "        16,  1, 16, 16, 16, 10, 10, 16, 16, 10, 16, 16,  6, 10],\n",
      "       device='cuda:0'), tensor([16,  4,  4, 10, 16, 16, 16, 16,  4,  4, 10, 13, 13,  4, 16, 16, 13,  7,\n",
      "        16, 16, 13,  9,  6,  5, 16,  5,  2, 10, 13,  9,  8, 10],\n",
      "       device='cuda:0'), tensor([13,  2, 13, 10, 10,  8, 16, 16,  8, 10, 19, 16, 10, 16,  2, 16, 16,  9,\n",
      "         4,  4, 19,  9,  5,  4,  9, 16, 16,  9, 16,  8,  9, 19],\n",
      "       device='cuda:0'), tensor([15, 16,  4,  2,  3,  3,  5,  5,  5,  2, 16, 19,  8, 16,  7, 10,  2,  5,\n",
      "         8, 17,  2,  8,  8,  4, 16, 16, 10, 19, 16, 16,  8, 16],\n",
      "       device='cuda:0'), tensor([19,  8,  3, 10,  8,  4, 10,  6, 18, 10,  9,  2, 16, 17,  5,  6, 10, 10,\n",
      "        16, 16,  9, 19,  2,  5, 13, 16, 19,  7,  7,  3,  8, 10],\n",
      "       device='cuda:0'), tensor([16,  9,  9,  9, 16,  8,  6,  3, 16, 16, 13, 16, 10, 16, 10, 16, 10, 10,\n",
      "        16, 10, 10, 16, 17, 16, 16, 10, 16, 16,  8, 18, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16, 16, 16, 10, 16,  2, 16, 10, 16, 16, 10, 16,  6,  4, 16,\n",
      "         8,  4, 10, 19, 16, 16,  3,  4, 16,  5,  4, 16, 16,  4],\n",
      "       device='cuda:0'), tensor([16, 16,  3, 16, 10, 10, 16, 10, 16,  5, 16, 16, 16, 16, 16, 10, 16, 16,\n",
      "        16, 16,  2,  6,  5,  5, 16, 16, 16,  7,  6,  6, 16,  4],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16, 16,  2,  3, 16,  4, 19, 10, 10,  6, 16, 10, 10, 13, 16,\n",
      "        16, 16, 16, 16, 13, 18,  5,  8,  2, 16, 16,  2, 16, 13],\n",
      "       device='cuda:0'), tensor([ 5, 11,  2,  2,  8, 10,  2,  5,  8,  6,  2,  9,  6, 10,  8,  4, 10,  5,\n",
      "         4, 10,  4, 16,  8, 10,  5, 17,  2, 19, 13,  2,  3, 13],\n",
      "       device='cuda:0'), tensor([ 9, 16, 10,  2,  2, 10,  9,  9,  2,  5, 16,  2, 16, 18, 10, 16,  8, 16,\n",
      "         8,  8, 10,  4, 10, 16, 10, 13, 19,  8,  8,  5,  3,  2],\n",
      "       device='cuda:0'), tensor([19, 10, 13, 19,  5,  4,  2, 10,  5,  4,  8,  9, 10, 10, 10, 10, 10,  2,\n",
      "        10,  3,  2,  8,  3, 10, 16, 18, 16, 16, 16, 10, 16,  5],\n",
      "       device='cuda:0'), tensor([ 6, 16,  4,  8,  2,  9, 19,  9, 16, 16, 16, 16, 16, 16,  8, 16, 16,  2,\n",
      "         4,  2, 10, 10,  5,  4, 16,  0, 16, 11,  0, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  4,  3,  2,  9, 16,  5, 16, 10,  8,  4, 16,  5,  8,  5, 16, 16, 10,\n",
      "         4,  8,  7,  8, 17, 16, 19, 16, 10, 16, 10,  9, 16, 16],\n",
      "       device='cuda:0'), tensor([ 4,  3, 16,  2, 16,  4,  7,  8, 19,  8, 10,  4,  8, 16, 13, 13, 16, 16,\n",
      "         4, 19, 16, 10, 16, 16,  2, 10,  5,  4, 16,  3,  4, 16],\n",
      "       device='cuda:0'), tensor([16,  6, 16,  8, 16, 13,  8,  8,  4,  4, 16,  5, 16, 19, 16, 10, 16, 11,\n",
      "        16, 16,  2, 19, 16, 16,  4,  4, 16, 16, 16, 10, 16,  8],\n",
      "       device='cuda:0'), tensor([19, 16,  4, 10, 16, 19, 16, 16, 16, 16, 13,  5,  4,  4, 10, 19, 16, 16,\n",
      "        19,  5, 16, 16, 16, 16, 16, 16,  4,  4, 16,  4, 16, 16],\n",
      "       device='cuda:0'), tensor([ 1,  1,  2, 16, 16, 16,  2,  9, 16, 16, 16, 13,  8, 16,  4, 16, 10,  8,\n",
      "        16, 16,  3, 16, 16, 16, 16,  8,  4, 10, 13,  3, 16,  5],\n",
      "       device='cuda:0'), tensor([16,  0, 16,  3, 13, 10,  5, 16,  3, 19,  7, 16, 19, 10, 16, 16, 10,  5,\n",
      "        10, 16, 13, 16, 16, 16,  5, 16, 16,  5, 16, 13, 19,  8],\n",
      "       device='cuda:0'), tensor([ 2, 16, 16, 16, 16,  4, 16, 16,  5, 10,  0,  2,  8,  8, 16, 16, 16, 16,\n",
      "        16,  9, 16,  2, 16, 19, 16, 10, 16,  5, 16, 16,  5,  8],\n",
      "       device='cuda:0'), tensor([16, 16,  2, 16,  8, 16, 16, 10,  5,  4,  3,  8,  9, 19, 19, 10, 10, 16,\n",
      "        10, 13, 16,  2,  9,  6, 11, 10, 10, 16, 19,  6, 10, 16],\n",
      "       device='cuda:0'), tensor([11,  4,  4, 10, 16, 16,  9,  5, 18, 16, 11,  8,  9, 10, 16,  5, 16, 11,\n",
      "        16,  3, 18, 16, 10, 16, 10, 16, 16, 16,  2, 16,  8,  4],\n",
      "       device='cuda:0'), tensor([10, 11, 16, 16,  0, 16,  4,  7, 13, 15,  6,  7,  2, 10,  4,  8,  4, 16,\n",
      "         8, 16,  4,  0,  9, 16, 16, 16,  5, 10,  2,  2,  9, 10],\n",
      "       device='cuda:0'), tensor([19, 10, 13,  5, 10,  7, 16, 11, 16, 16, 16, 16, 10, 17, 16, 16,  4, 16,\n",
      "        16,  2, 16,  3, 16, 16, 16,  2, 16,  8,  7,  4,  4,  3],\n",
      "       device='cuda:0'), tensor([ 4, 16,  6, 16, 16, 15,  4,  4, 16, 16,  5, 16, 16, 16, 10, 16, 16, 16,\n",
      "         5, 16, 16,  3,  3, 16,  2, 16, 16,  8, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 4,  3, 16, 16, 16, 10, 10, 16, 16, 16,  7, 10, 13, 18,  9, 16, 16, 10,\n",
      "         8,  4,  3, 16, 16,  4, 19, 16, 13, 16, 16,  4, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  6, 16, 10, 16, 16, 16,  5,  4, 16, 16, 16, 16,  2,  4, 16,  4,  5,\n",
      "         5, 10, 16, 10, 16,  9, 16,  2, 10, 11, 11, 18,  4,  4],\n",
      "       device='cuda:0'), tensor([ 6, 16,  4, 16, 16, 19,  6, 10,  4, 10,  6,  4,  9,  2,  8,  8, 13,  9,\n",
      "         5,  2,  6,  9,  2, 10, 16,  8,  8,  6,  5, 13,  3,  4],\n",
      "       device='cuda:0'), tensor([19, 10,  4, 16,  3, 16,  5,  8,  1,  1,  2,  1,  5, 18,  3,  2, 16,  2,\n",
      "         8,  2,  8,  0, 10,  2, 16,  4, 13,  6, 10,  2,  5,  2],\n",
      "       device='cuda:0'), tensor([16, 16,  5,  3, 10,  4,  8,  4,  2,  9,  2,  8,  4, 10,  8,  2, 16, 19,\n",
      "        10, 16, 13, 16,  3, 18, 10,  2,  4,  8, 10, 18, 16,  2],\n",
      "       device='cuda:0'), tensor([ 5,  6,  8, 16, 16, 16, 10, 16, 19, 13,  5, 16, 10,  3,  8,  7,  9, 16,\n",
      "         4, 18,  2,  7,  5,  8, 16, 18, 10, 16, 16,  5, 18, 10],\n",
      "       device='cuda:0'), tensor([ 2,  6,  4,  9, 16,  4, 10, 10,  4, 15, 16, 16, 16, 19, 18, 16, 10,  7,\n",
      "        16, 16,  2, 16, 10, 10, 16,  2, 16,  5,  4, 16, 16,  2],\n",
      "       device='cuda:0'), tensor([ 6, 16, 16, 19,  5,  3, 16, 16, 16,  5, 16, 16, 18,  0, 16,  4, 19,  5,\n",
      "        10, 16, 11, 16, 16, 16, 16, 19, 16,  1,  9, 10,  8, 15],\n",
      "       device='cuda:0'), tensor([ 5, 16, 16, 16,  4, 16, 16,  0, 10, 19, 16, 19, 16, 16,  8, 19,  2,  5,\n",
      "        16, 16, 16,  2, 16, 16,  7, 19, 16, 18, 16,  3,  4, 16],\n",
      "       device='cuda:0'), tensor([10, 13, 16, 16,  5, 19,  2,  4,  3, 16,  3, 16, 13, 10,  9,  8,  8, 16,\n",
      "         4, 18, 19,  8, 10, 16, 16,  4,  5, 10, 10,  2, 10, 16],\n",
      "       device='cuda:0'), tensor([10,  4,  7, 16,  5, 16,  4, 16, 16, 16,  5, 15,  4, 16, 13, 16, 11, 16,\n",
      "        16,  1,  5,  8, 16, 10, 16,  8,  4, 10, 16,  4, 16, 16],\n",
      "       device='cuda:0'), tensor([ 8, 16, 16, 16,  6, 16, 16, 16, 16, 10, 16, 10, 16, 16, 16, 16, 16, 16,\n",
      "        16,  3, 13, 16,  5,  4, 16, 16, 10, 16, 16, 16,  3, 16],\n",
      "       device='cuda:0'), tensor([16,  4,  0,  9, 10, 16,  3, 16,  1,  5,  0, 16, 13,  4, 16,  4, 16, 16,\n",
      "         4, 19, 10, 16, 16, 16,  4, 16, 16, 16, 16,  9,  8, 16],\n",
      "       device='cuda:0'), tensor([ 2, 16,  3, 16,  0, 16, 16, 16, 10, 16, 16, 16,  4, 16,  8, 16, 16,  6,\n",
      "        10, 10, 16, 16, 16,  8, 10,  8,  9,  8, 16, 16,  3,  3],\n",
      "       device='cuda:0'), tensor([18, 16, 10,  4, 10, 10, 16, 19,  4, 16, 16,  6,  8, 16,  8,  4, 19,  2,\n",
      "         4,  5, 11, 19, 10, 16, 14, 10, 16, 16,  8, 10, 16, 10],\n",
      "       device='cuda:0'), tensor([ 5, 19,  4,  5, 11,  2,  2,  2, 10, 10, 10, 10,  8,  8,  4, 16,  4, 16,\n",
      "         8, 16,  9, 19, 16,  2, 16,  8, 16, 16,  9, 10, 16, 16],\n",
      "       device='cuda:0'), tensor([ 5,  9, 11, 10, 16,  8, 16,  9,  4, 19,  5, 13, 10,  6,  2,  8,  4,  8,\n",
      "         8,  6, 16, 16,  5,  2,  3,  3,  8, 16,  8,  8, 10, 10],\n",
      "       device='cuda:0'), tensor([ 2, 10,  2, 10, 10, 16, 10,  2, 10,  8,  4,  8,  9, 16,  9, 10,  5,  2,\n",
      "        16, 10, 11,  6,  8,  0,  2,  9, 16, 10,  9,  2,  9, 10],\n",
      "       device='cuda:0'), tensor([18, 16, 16,  2,  9,  5, 16,  4,  8, 10, 10,  2, 16,  6, 16, 16, 16, 10,\n",
      "         8, 16,  8, 10, 16, 16,  2,  8, 16, 16,  2,  8, 10, 16],\n",
      "       device='cuda:0'), tensor([10,  4, 16, 16, 16,  8, 16, 16,  4, 13,  3, 16, 13,  6, 13,  5,  4, 16,\n",
      "         9, 16,  4,  8, 18,  5, 16, 10, 10,  4, 16, 18, 16, 19],\n",
      "       device='cuda:0'), tensor([16, 10, 16, 13, 19, 19,  8, 19,  4, 16,  4, 16, 13, 16,  5,  8, 16, 10,\n",
      "        16, 16,  6,  4,  6, 16, 16, 16, 16,  8, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 3, 16,  3, 16, 13,  4,  4, 16, 16,  7, 16, 18,  2,  8,  4,  3, 16,  4,\n",
      "        19, 16, 19,  5,  0,  4, 13,  4,  4,  1, 10, 13, 10, 13],\n",
      "       device='cuda:0'), tensor([ 4,  9,  2, 10,  4,  4,  8, 19,  2, 10,  3, 10,  2,  5,  3,  4, 13,  5,\n",
      "        16, 19,  9, 10,  8,  4,  2,  8,  8,  3, 19,  8,  2,  1],\n",
      "       device='cuda:0'), tensor([ 3,  5,  2,  8,  5,  0,  2,  8, 16, 11, 19, 16, 10, 13,  8,  2, 16, 13,\n",
      "        10, 16,  2,  8, 10, 16, 10, 19, 16, 10, 10, 16,  9,  3],\n",
      "       device='cuda:0'), tensor([ 4, 18,  1, 16, 16, 16,  0,  5,  3,  3, 19,  9,  8,  8, 16, 16, 16,  3,\n",
      "         8,  0, 16, 11, 16,  8, 13,  2,  5,  4, 16,  8,  8, 16],\n",
      "       device='cuda:0'), tensor([ 3,  2, 16, 10, 19,  2, 10,  8, 17,  6,  4, 16, 19, 13,  3, 10, 16,  4,\n",
      "         5, 16, 16,  4, 16, 10,  5, 16,  7,  5, 19,  5,  5, 10],\n",
      "       device='cuda:0'), tensor([16,  9, 16, 16, 16,  4,  2,  8, 16, 16, 16,  8, 16,  2, 16, 16, 15,  3,\n",
      "        16, 16, 16,  6,  4,  9, 11, 16,  5, 11, 16,  8,  5, 16],\n",
      "       device='cuda:0'), tensor([10, 16, 16,  8, 16, 16,  4,  3, 16, 10, 13,  4, 16,  4, 19,  4, 16, 19,\n",
      "        16, 16,  9,  9,  9, 16, 16, 10, 16,  3, 16, 16, 16, 10],\n",
      "       device='cuda:0'), tensor([ 9, 16,  5,  8, 19, 19,  4,  5,  2, 16, 19,  4, 16, 16,  9, 16, 19, 16,\n",
      "         2, 16,  6, 16, 16, 18, 16, 16, 16, 16, 19, 16, 10,  3],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16, 16,  7, 19, 16, 16, 16, 16,  4, 16,  5,  6,  4, 13,  3,\n",
      "        16, 16, 16,  9, 19, 16, 16, 10,  7, 16, 19, 13, 16,  2],\n",
      "       device='cuda:0'), tensor([ 4, 13, 19, 13,  5,  5, 16,  4, 16, 16,  8, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 10, 16, 16,  8,  5,  5,  2, 16, 16,  3,  4,  2, 16],\n",
      "       device='cuda:0'), tensor([10,  2,  5, 16,  2, 16,  5, 16,  4, 13,  5, 10, 19, 16, 16,  4,  2, 16,\n",
      "        16, 19,  4,  8,  5, 16, 19,  5, 16, 16, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  4, 16,  4, 16, 16, 19, 16,  8, 16, 16, 16, 16, 16,  2, 10,  5, 13,\n",
      "         5, 13,  8, 16, 16,  5, 19, 10, 13, 16, 16,  8, 19,  8],\n",
      "       device='cuda:0'), tensor([ 0, 16,  4,  4,  5,  5,  2, 16,  5,  8,  5, 10,  1, 16, 16, 16,  2,  5,\n",
      "         5,  5, 10, 18, 10,  4, 10, 16, 16,  4, 10,  8,  5,  2],\n",
      "       device='cuda:0'), tensor([16, 19, 10,  2, 16, 16,  2,  5, 16,  9, 17,  2,  8,  5, 16,  2, 19, 16,\n",
      "         3, 16,  9,  9, 10, 16,  9,  3,  8,  8,  2,  6, 19,  9],\n",
      "       device='cuda:0'), tensor([16, 13, 16, 16,  9,  2,  5, 15, 10, 15,  8,  9, 16,  8,  6, 10, 16, 16,\n",
      "        16, 16, 16, 10, 16, 10, 13, 16,  4, 16, 16,  4, 16, 16],\n",
      "       device='cuda:0'), tensor([17, 16, 16,  6, 13, 16, 10,  3, 16, 10, 16, 16,  4, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16,  7, 10,  4, 10,  9, 16, 16, 16,  5, 16],\n",
      "       device='cuda:0'), tensor([17,  3, 16, 10, 16,  4, 16, 10, 16, 10, 16, 10, 10, 16,  8, 16, 13, 16,\n",
      "        18, 16,  4, 16, 16, 10, 16, 10, 16, 16, 16, 16, 16,  5],\n",
      "       device='cuda:0'), tensor([13, 16, 16, 16,  8,  5,  2,  4,  5, 16, 16,  4,  4, 10,  5, 16, 10, 10,\n",
      "        16, 16,  5,  8,  4,  5,  9,  4, 16, 16, 16,  4, 19, 10],\n",
      "       device='cuda:0'), tensor([ 8,  6,  2,  2, 10, 19,  2, 16,  2, 16, 10,  2,  8, 10, 13, 16,  4, 16,\n",
      "         2,  4,  8, 16, 13,  2, 13,  4,  8, 10,  8, 10, 19,  8],\n",
      "       device='cuda:0'), tensor([13,  4, 16, 10, 19, 10, 16, 16, 16, 14,  2,  1,  9,  4, 10,  4,  6,  2,\n",
      "         7,  8,  2, 18,  2, 16,  3, 18,  2,  8,  2,  8,  0,  4],\n",
      "       device='cuda:0'), tensor([10, 13,  5,  2, 16, 13, 19, 13, 16, 13,  2, 10,  8, 10,  2,  5, 13, 16,\n",
      "        10,  5, 16,  4,  5,  8,  2, 16,  9, 19,  8,  2,  2, 10],\n",
      "       device='cuda:0'), tensor([16,  2,  2, 16,  8, 16, 19,  2, 16, 19, 16, 16, 16,  4, 16,  1,  3,  9,\n",
      "        16, 16, 19, 16, 10, 14,  8, 16,  8, 16,  5,  3, 16,  3],\n",
      "       device='cuda:0'), tensor([16, 16,  5,  8,  2, 16, 16, 19,  2,  4, 16,  8,  6, 16, 16,  6, 16,  1,\n",
      "        16, 16,  4,  0, 10,  8, 19, 16,  2,  9, 10,  9,  6, 16],\n",
      "       device='cuda:0'), tensor([ 8, 16, 16,  2, 18, 10, 16, 16,  2,  8, 16,  8, 19, 16,  5, 13,  6,  4,\n",
      "        18, 16, 16,  0,  2,  8, 19, 16,  4,  8,  5, 19,  8,  3],\n",
      "       device='cuda:0'), tensor([ 6, 13, 13, 19,  9, 16, 16, 13, 16, 16, 16,  7, 19, 16, 16, 18,  5, 11,\n",
      "        16,  4, 16, 16,  4, 16, 16,  5, 16,  2, 10, 19,  4,  8],\n",
      "       device='cuda:0'), tensor([ 8,  3,  3, 16, 16, 16, 16, 16, 16, 18,  2,  4,  2,  5, 13,  6,  5, 14,\n",
      "        10,  4, 18, 10, 16, 16, 17, 13,  4, 16, 16,  6, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  4, 16, 18,  4,  4, 16, 13,  9, 10, 10, 16, 13,  3,  4,  9, 16, 16,\n",
      "         5,  2, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16,  4, 16],\n",
      "       device='cuda:0'), tensor([ 8, 16,  4, 10, 16, 10, 10, 13, 16, 16, 16, 16, 13,  4, 10, 16,  8,  3,\n",
      "         8,  4,  3,  5,  3, 16, 16,  4,  2, 10, 16,  5, 16, 19],\n",
      "       device='cuda:0'), tensor([16,  4,  4, 16, 16,  4, 16, 16,  2,  4, 16, 16, 16,  5, 16,  1, 16,  3,\n",
      "         8,  8, 16, 10, 16,  8, 16, 13, 16, 16, 18, 13,  5, 16],\n",
      "       device='cuda:0'), tensor([16,  9, 16, 19, 10, 16,  2,  2, 10,  2, 16,  4, 16,  2, 18, 13, 10,  0,\n",
      "        16,  6, 16,  4, 16, 16,  5, 16,  9, 16, 16, 16, 10,  4],\n",
      "       device='cuda:0'), tensor([10,  8, 13, 16,  5, 10, 16, 10,  2,  3, 16, 13, 16, 16,  3,  5, 11, 16,\n",
      "         6, 16,  5,  8,  4, 16, 16, 16, 10,  8,  5,  2,  2,  4],\n",
      "       device='cuda:0'), tensor([16, 10, 16,  9,  3, 16, 16,  8, 16, 16,  5, 16, 10, 16,  5, 19,  4, 16,\n",
      "         4, 16, 11, 10,  4,  8,  8, 16, 16, 16,  3, 16,  2,  5],\n",
      "       device='cuda:0'), tensor([10, 16, 16,  4, 13, 16,  8, 16, 18, 16,  4, 10, 16, 10, 16,  6, 13, 19,\n",
      "        10,  8, 16,  4,  9, 16,  8,  8,  2, 16,  3,  5,  3, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 13, 16,  1,  1, 16,  8,  9, 16, 16, 13, 16,  3,  4,  3,  5, 16,\n",
      "        15,  8,  8,  4, 10, 16, 16, 10, 18, 10, 11,  0,  5, 10],\n",
      "       device='cuda:0'), tensor([10,  8,  2, 11, 16, 16,  4, 16,  4,  7, 16, 11,  3, 10, 16, 16, 16,  4,\n",
      "        16, 16,  4, 16, 16, 16,  5, 16, 16, 16, 16,  5,  8, 16],\n",
      "       device='cuda:0'), tensor([ 8,  7, 16,  8, 16, 16, 13, 10, 16, 16,  4,  4, 13,  4,  2, 16, 16, 16,\n",
      "        16,  3,  5,  4,  3,  9,  8,  8,  6, 18,  4, 16,  4,  3],\n",
      "       device='cuda:0'), tensor([16,  5, 16, 10, 16,  4, 16, 17, 16, 13,  4,  9,  5, 16,  2,  4, 16, 16,\n",
      "         0,  4,  2, 19, 10,  8,  8,  9, 13,  6, 13, 16,  8,  7],\n",
      "       device='cuda:0'), tensor([10, 10, 19,  8, 10, 16, 10,  9, 10,  4,  9,  8, 16,  3, 13, 16,  3, 10,\n",
      "        16, 10, 10,  4, 16,  2, 10, 19,  5,  4, 16,  9,  9, 13],\n",
      "       device='cuda:0'), tensor([14,  9,  6,  5, 13,  2, 15, 16,  8,  4, 13, 10, 14,  2,  5, 13, 16,  8,\n",
      "         0,  4,  4,  9, 11, 16, 13,  2, 13,  5, 16, 10,  8,  8],\n",
      "       device='cuda:0'), tensor([16,  6, 10,  8,  4, 16,  5, 16, 16,  2,  9,  3, 16,  5,  3, 16, 19,  6,\n",
      "         5, 10,  2, 19, 13,  4,  8, 16,  3,  8,  9,  8,  0, 16],\n",
      "       device='cuda:0'), tensor([ 4, 10,  8,  8, 10,  9,  2, 18,  5,  2, 16,  4, 10,  9, 16,  2,  3, 19,\n",
      "        19, 18, 10,  5,  4,  4, 16, 16, 10,  9,  8, 16, 17, 16],\n",
      "       device='cuda:0'), tensor([13, 19, 16, 16,  8, 17, 19,  9,  4, 19, 16, 17, 16, 16, 16, 16, 16,  8,\n",
      "        10, 14,  2, 10, 16, 16,  8,  4,  9, 16, 16, 16,  4, 10],\n",
      "       device='cuda:0'), tensor([16, 10,  6,  5,  8, 10,  8, 16, 18, 16,  5,  8, 19,  5,  5, 16, 16,  9,\n",
      "        16, 16, 16, 16,  8,  2,  1, 16, 19, 13,  8, 16,  5, 16],\n",
      "       device='cuda:0'), tensor([ 5,  9,  3,  5, 16, 19,  8,  3,  5, 16, 19, 16, 16, 16, 16,  3, 16, 16,\n",
      "        16, 16, 19, 10, 16, 16, 16, 16, 16, 16, 16,  4, 10, 16],\n",
      "       device='cuda:0'), tensor([ 8, 16, 18, 16, 16, 18,  5, 16, 17, 16, 16,  4,  2, 16,  4,  9,  3, 16,\n",
      "         4, 16,  5, 10,  4, 16, 16, 16, 19, 16, 16,  6, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 13, 16, 16, 16, 16, 16, 16, 10, 10, 16,  3,  6,  8, 19, 16, 16,  3,\n",
      "         5, 16,  8,  8,  5, 19, 16, 16,  4,  8, 13, 16, 19, 16],\n",
      "       device='cuda:0'), tensor([10, 16, 19, 10, 16, 16, 15,  6,  6,  5, 16, 16, 10, 16, 16, 16,  4, 16,\n",
      "        10,  8, 16, 16, 16, 16,  5,  4, 16,  4, 19, 19, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 13,  9,  2, 10, 10,  3,  5,  9, 10, 16, 16,  4,  9,  9, 16, 16,\n",
      "         8,  2, 16,  8, 11,  5, 10, 16,  2,  9,  2, 16, 19, 16],\n",
      "       device='cuda:0'), tensor([ 8, 10, 10,  3,  8, 10, 10, 10, 16, 16, 16, 16, 13,  9,  2, 10, 10,  2,\n",
      "        10, 16,  5, 16,  8,  5, 16,  4,  5, 16, 16, 19, 16,  4],\n",
      "       device='cuda:0'), tensor([10, 10,  8,  2, 16,  4,  2,  8, 16,  1, 19, 10,  8,  8,  8, 10,  4,  5,\n",
      "         2,  7, 16, 10, 10,  9, 16,  8,  2,  8, 16,  5, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 10,  9, 19,  4,  4,  2,  8, 19,  5,  2,  5,  0,  8,  6, 10,  2, 16,\n",
      "        10, 16, 19, 16,  4, 16, 16,  4, 16,  8,  4,  3, 16,  4],\n",
      "       device='cuda:0'), tensor([11, 16, 16, 16,  6, 16,  2,  5, 16, 16, 10,  4, 13, 16, 16,  5, 13,  5,\n",
      "        16, 15,  5, 16,  5,  4, 16,  5, 16, 16, 15,  5,  8, 11],\n",
      "       device='cuda:0'), tensor([16,  3, 16,  3, 13, 13,  8, 13, 16, 15, 18,  4,  1,  8,  7,  3,  4,  8,\n",
      "         2, 16,  1,  7, 16, 16,  8,  8,  3,  5, 16,  6,  5, 16],\n",
      "       device='cuda:0'), tensor([ 5,  9, 10, 16, 11,  8, 10,  8,  3, 16, 16,  5, 13, 16,  0, 16, 10, 16,\n",
      "        16, 10,  3, 16,  8,  4,  5,  2, 16, 15, 16,  2,  5,  8],\n",
      "       device='cuda:0'), tensor([ 2,  2,  4, 10,  8, 16,  3,  9,  8,  5, 16,  8,  5, 10,  8, 16,  9, 16,\n",
      "        19, 10,  2, 19,  3,  8, 19,  2, 13, 16,  8, 11,  9,  9],\n",
      "       device='cuda:0'), tensor([16,  6,  4,  5, 18,  8,  2, 18,  5,  2,  3, 15,  8, 13,  8,  2, 19,  2,\n",
      "        10,  2,  8, 16,  2, 16,  3,  8, 10,  9,  9,  4, 16,  8],\n",
      "       device='cuda:0'), tensor([ 8,  5, 13,  2,  2,  5,  8,  0,  3,  2, 19, 16, 16,  5, 19,  8, 19, 16,\n",
      "         7, 16, 13,  8, 10, 13, 16, 16,  2, 16, 13,  0,  4,  5],\n",
      "       device='cuda:0'), tensor([10, 14,  9,  5, 16, 16,  4, 10,  5, 16,  8, 16, 16, 16,  5,  6, 16, 16,\n",
      "         9,  0, 16,  5,  8,  8, 15, 19, 16, 19,  5, 16,  2,  5],\n",
      "       device='cuda:0'), tensor([ 2, 16, 19, 16, 13,  9,  9, 16, 19,  8, 16,  2, 10, 16, 16, 16, 16, 16,\n",
      "        16, 10,  4, 16,  4, 16, 16, 16, 16, 13, 16, 19, 16, 10],\n",
      "       device='cuda:0'), tensor([ 3, 16, 19, 16, 16, 16,  3, 16, 16, 16,  4, 10,  8, 13, 16, 19, 16, 16,\n",
      "        16,  4, 16, 16, 16, 16,  4, 16, 17,  8, 16, 16, 16, 10],\n",
      "       device='cuda:0'), tensor([ 2, 16, 10,  2, 16,  6,  8, 10, 16, 19,  8, 16,  8,  4, 10,  8,  2,  5,\n",
      "        13, 16,  6, 16,  2,  1, 16, 16, 16,  3, 18,  4, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 10, 16,  4, 16, 16,  3, 16, 16, 16, 10, 13, 16,  2,  4, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 10,  3,  4,  4, 16, 16, 16,  4],\n",
      "       device='cuda:0'), tensor([10,  4, 16,  5, 16,  8,  3, 10,  8, 16,  2,  3,  8, 16,  7, 16, 10, 16,\n",
      "        16, 16, 16,  5, 16, 16, 16,  4,  4, 18,  6,  3, 10, 10],\n",
      "       device='cuda:0'), tensor([16,  4,  3,  4, 19, 10, 16, 16,  8,  4,  7,  4, 16, 10,  4, 16, 10, 16,\n",
      "        16, 16, 16, 16, 19, 16, 16, 10, 16, 16,  2,  2, 16,  9],\n",
      "       device='cuda:0'), tensor([16, 16,  2, 16, 10, 10, 16,  1, 13,  4, 16, 10, 10,  8, 10, 16, 18, 10,\n",
      "         8,  9,  2, 16, 10, 16, 10,  4,  9,  9, 16, 16, 16, 19],\n",
      "       device='cuda:0'), tensor([ 8,  8, 16, 16, 10, 19, 16, 16, 11, 16, 13, 16,  4,  2,  6, 16, 16,  3,\n",
      "        10, 16, 10,  8,  1,  2,  8,  3,  8,  5,  4, 10, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  9, 16, 16, 16,  9,  2,  2,  9,  4,  5, 10,  8,  5,  5, 10, 19, 16,\n",
      "        19, 10,  3,  7, 14,  7, 16, 16,  8, 10,  5,  2,  8, 10],\n",
      "       device='cuda:0'), tensor([16,  4, 15,  2,  4, 10,  5, 10,  4,  8,  2, 13, 16,  4,  2,  2, 16, 10,\n",
      "        16, 16,  5,  5,  8, 16, 10, 16, 16,  2, 16, 16,  2, 16],\n",
      "       device='cuda:0'), tensor([ 8, 16, 16, 16, 16, 16, 16, 10, 10,  4, 16, 16,  4, 16, 16, 10, 16, 13,\n",
      "         5, 16, 10, 16,  8,  4, 16, 16, 16,  3, 10,  9, 16, 16],\n",
      "       device='cuda:0'), tensor([ 7, 13, 11, 16, 16, 16, 16, 16,  4,  8, 16, 10, 16, 16, 16, 19, 16,  5,\n",
      "         3, 16,  3, 16, 16,  5, 16, 16,  8, 16, 10, 16, 16, 10],\n",
      "       device='cuda:0'), tensor([ 8, 16, 16, 16, 16, 16, 10, 16, 10,  2, 16, 16, 13, 16, 16, 19, 10,  8,\n",
      "        11,  2,  8,  1,  8, 13,  8,  4, 16, 16,  4,  3, 10,  9],\n",
      "       device='cuda:0'), tensor([ 9,  8, 10, 19,  8,  5,  5,  4,  2, 19, 16, 11,  3, 10,  9, 16, 19,  8,\n",
      "        10,  2, 18, 13,  8, 16,  8,  2,  8,  8,  2,  8,  0,  4],\n",
      "       device='cuda:0'), tensor([ 8,  2,  7,  4,  8,  4,  6, 19,  8, 10, 16, 16,  8, 16,  8,  8, 15, 16,\n",
      "         0, 10, 16, 10, 16,  4, 10,  2, 10,  6, 13, 13,  0, 16],\n",
      "       device='cuda:0'), tensor([16,  8,  0, 19,  5,  8, 16, 16,  4, 13,  3, 16,  2,  4, 16, 16, 16,  8,\n",
      "         2, 16, 16,  2,  6, 13, 16, 10, 13, 16, 10, 10,  5, 10],\n",
      "       device='cuda:0'), tensor([16,  9, 13, 10,  8,  8, 16, 16,  3, 16, 16, 16,  8,  4, 16, 19, 16, 13,\n",
      "         5, 16,  3,  8, 16,  2, 16,  2, 16, 10, 16, 10,  2,  5],\n",
      "       device='cuda:0'), tensor([19, 16,  8, 16, 10, 16, 16,  4, 16,  2,  8, 16, 16, 16, 13,  5,  4,  2,\n",
      "        16, 16,  8,  6,  5, 16,  2, 16,  4, 16, 19, 10, 16, 16],\n",
      "       device='cuda:0'), tensor([ 8, 16, 16,  9, 10, 16,  8, 16, 10, 16, 16,  5,  8, 16, 16, 16, 16, 10,\n",
      "        10, 10, 19,  2,  4,  5, 15, 16,  5, 16, 16, 16, 11, 16],\n",
      "       device='cuda:0'), tensor([ 3, 16, 16,  3,  6, 16, 16, 16, 16, 16, 16, 13, 10,  6,  4, 16, 16,  4,\n",
      "         8, 19, 10,  5, 16, 13,  3,  5, 19, 19,  4, 16, 16,  5],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16, 16,  8,  2,  4, 18, 16, 16,  4, 16, 16, 10, 16, 16, 16,\n",
      "        16,  4, 16, 16, 16, 16, 16,  4, 16,  8, 16, 16,  2, 16],\n",
      "       device='cuda:0'), tensor([13,  5,  5, 16, 16, 16,  1, 19, 16, 16, 16, 16, 16, 10, 16, 16, 16,  5,\n",
      "        16, 13, 13, 16, 16,  8, 18,  2, 16, 11, 16,  3, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16, 16, 16,  3, 16, 16,  9, 16,  2, 16, 16, 16,  5, 16,  4,\n",
      "        10, 16, 16,  5, 10,  5,  6,  4, 16, 11, 16, 16,  9, 16],\n",
      "       device='cuda:0'), tensor([19,  5,  5,  9, 16, 16, 16,  0,  2,  2, 16,  4,  3, 13,  9,  9,  3,  2,\n",
      "        10,  4,  4,  4,  9, 16, 10, 10,  4, 16, 16,  2,  5, 16],\n",
      "       device='cuda:0'), tensor([16,  2,  2,  3, 14,  8,  2, 16, 16, 16,  5, 16, 16, 16, 16, 16,  5,  2,\n",
      "        19, 19, 16,  8, 16, 16, 18,  2,  4,  8, 19,  8,  2, 16],\n",
      "       device='cuda:0'), tensor([19, 16,  8,  9,  4,  3, 16,  4, 16, 10,  9,  9,  8,  0, 16, 10, 19, 16,\n",
      "        10, 13,  2,  6, 16,  8,  8, 16, 16,  2, 16,  4,  9, 16],\n",
      "       device='cuda:0'), tensor([ 5,  9, 16,  5,  3, 16, 16,  2, 16, 16, 16,  6, 16, 13, 16, 16, 16,  8,\n",
      "        13, 16, 16, 16, 16, 11,  5,  2, 16, 16, 13, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([10,  3, 16,  4,  2,  6,  4,  4,  8,  5, 16,  2, 16, 16, 16,  2, 16,  8,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 10,  2,  5, 10,  4, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16,  4,  3,  8, 16,  5, 10,  3,  6,  7,  9, 16, 16, 16, 13, 16,\n",
      "         9, 16,  8,  0, 16, 16, 16,  0, 16, 16, 10,  5, 16, 16],\n",
      "       device='cuda:0'), tensor([ 5, 16, 16,  3,  8, 10, 13, 16, 16,  1, 13,  5, 10,  4,  2, 16, 16,  3,\n",
      "         5,  5,  9, 10, 10,  9,  8,  2, 10,  8, 11, 10,  3,  5],\n",
      "       device='cuda:0'), tensor([ 5, 16,  2, 10, 16,  3,  2, 10, 16, 10, 13, 19,  4,  2,  4,  0,  2, 16,\n",
      "        16,  2, 11, 13,  2,  8, 16, 17, 16,  2,  5, 16,  2, 16],\n",
      "       device='cuda:0'), tensor([19, 16,  7, 10, 19, 16,  2, 10, 16,  2,  4,  9, 10, 14, 10, 16,  8, 18,\n",
      "         4, 16,  4, 16,  3, 13, 16,  7, 10,  4, 13, 10,  9,  3],\n",
      "       device='cuda:0'), tensor([10,  4, 16, 19, 16,  5,  6, 19,  2,  8, 16,  9,  8, 17, 11,  4, 19,  8,\n",
      "        10, 19, 10, 16,  2,  5, 16,  5,  2, 16,  4,  3, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 11,  5, 10,  4, 10,  8, 10,  9,  2, 16, 10, 16, 10, 16, 16,  3, 13,\n",
      "        16, 16,  2,  8,  2, 19, 13, 10, 16, 16, 16, 13,  8, 16],\n",
      "       device='cuda:0'), tensor([16, 10, 16, 16, 16, 10, 16,  4, 16, 10,  5, 16, 13,  2,  2, 16, 16, 15,\n",
      "         4, 16, 16, 10, 16, 16, 10, 13, 16, 16, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 19,  2,  5, 10, 16, 16,  8, 16, 16, 10,  6,  2, 16, 10,  4,  3, 16,\n",
      "        16,  5, 10,  9, 16, 16,  4, 16, 16,  3,  2, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16,  4, 16, 16, 10, 16,  9, 16,  8, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16,  4, 10,  4,  4, 16, 16,  8,  9,  0, 16, 16,  5, 13],\n",
      "       device='cuda:0'), tensor([16, 16, 16,  8,  9,  8, 16,  9,  9, 16,  1, 16,  4, 10, 16,  4, 16, 19,\n",
      "         0, 17,  8, 16,  4, 10, 16, 10,  4, 16, 10, 18, 16, 16],\n",
      "       device='cuda:0'), tensor([ 3,  2, 16, 16,  6, 16, 10,  8, 16, 16, 16, 16, 16, 16,  8, 16,  9, 16,\n",
      "         4,  4,  4,  8,  9, 16, 16, 16,  8, 16, 16,  4, 10,  4],\n",
      "       device='cuda:0'), tensor([16,  4,  4, 16, 16,  1,  5, 10, 16,  8,  5, 10,  8, 16, 16, 16, 10, 16,\n",
      "         5, 16,  5, 16, 19, 16, 16, 16, 16, 16, 16,  8,  9,  4],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 19, 16, 16,  8,  4,  5, 16, 16,  2,  8, 16,  2, 17,  2, 10,\n",
      "        16,  4,  9,  2, 16, 16,  2, 19, 16,  5, 16, 10,  8, 10],\n",
      "       device='cuda:0'), tensor([16,  6,  2, 16, 16,  8, 16, 10, 10, 16,  4,  8, 10, 16,  9, 10, 10,  8,\n",
      "        16,  2,  6, 13,  8,  9,  9, 10, 13,  9, 13,  9, 10, 16],\n",
      "       device='cuda:0'), tensor([17,  8,  4,  4, 16, 16,  8,  4, 10, 16,  8, 16, 13, 16,  2, 16, 19, 10,\n",
      "        16,  2, 14, 16, 14,  4,  5,  2,  5,  4, 16,  9,  8, 16],\n",
      "       device='cuda:0'), tensor([16,  2, 16,  6,  8, 10, 16, 16,  5, 16, 10, 16, 16,  9, 10, 16, 13, 16,\n",
      "        10,  4,  3,  8, 10, 10, 16, 18,  8,  8,  2,  8, 16, 16],\n",
      "       device='cuda:0'), tensor([ 8,  8,  8, 13,  2,  8, 16,  9, 19, 18, 16, 16, 16, 10, 16,  4, 16, 16,\n",
      "        16,  9, 16, 10, 10,  9,  2,  2, 16,  4, 16,  2,  5,  2],\n",
      "       device='cuda:0'), tensor([ 8,  1, 16, 16, 16, 16,  8,  5, 16, 16, 16, 16, 18,  8, 16, 16, 16,  4,\n",
      "         4, 16, 16,  5, 16, 16, 16, 13, 16,  5, 16, 16, 16,  6],\n",
      "       device='cuda:0'), tensor([16,  8, 16,  8, 16, 10, 16, 16, 16, 10, 16,  4, 16, 16, 10, 16,  5, 16,\n",
      "         3,  8, 16, 16,  3, 16, 16,  5, 10, 16, 16, 16,  6, 16],\n",
      "       device='cuda:0'), tensor([ 3, 16,  1, 16, 13, 16, 16, 10, 16, 16, 16, 16,  4,  9,  2,  4, 16, 10,\n",
      "        16, 16,  8,  4, 16,  5,  6, 16, 16, 11, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16,  8,  4, 16, 16,  4, 16, 16,  4, 16,  3,  4, 16, 10, 16, 16, 16,\n",
      "         4, 14,  8,  8,  6, 10,  5,  4, 16,  8,  2, 16,  5, 16],\n",
      "       device='cuda:0'), tensor([ 2, 16,  0,  4, 10,  2,  8,  4, 10,  9, 10, 10,  4,  2,  2,  8, 13, 11,\n",
      "        16, 16, 10, 16,  2,  5,  4,  2, 13, 19, 10, 16,  8, 16],\n",
      "       device='cuda:0'), tensor([ 6,  2,  2,  5,  5,  2,  8, 14, 19,  2, 18,  2, 16, 16,  2,  2, 19, 18,\n",
      "        16,  4,  3,  4, 18,  2, 10,  4, 18, 19,  4, 16, 13,  3],\n",
      "       device='cuda:0'), tensor([16,  8, 10,  0,  5,  2,  4,  9,  0, 16, 16,  8, 16, 10,  8,  9, 19,  5,\n",
      "        13,  8,  7, 16,  7, 10,  2, 17,  6, 14, 16, 19,  2,  9],\n",
      "       device='cuda:0'), tensor([ 5, 10, 16, 16, 16,  5, 19, 18, 10,  8, 10,  5,  6, 19, 19, 10,  1,  7,\n",
      "         4, 16,  5, 16, 16,  2,  5,  8, 15, 13, 16, 10, 16,  3],\n",
      "       device='cuda:0'), tensor([ 8,  9,  4, 16,  2, 16, 16, 17, 19, 10,  6, 10,  8, 16,  5,  7, 16, 10,\n",
      "        16, 16, 16, 10,  0, 16,  5, 16, 13, 16,  2,  4, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  4, 16, 16,  4,  4,  1, 16, 19, 16, 16,  2, 16, 16, 18, 16,  3, 10,\n",
      "        16, 16, 16, 10,  6, 16, 16,  5, 16,  8, 16, 15,  2, 16],\n",
      "       device='cuda:0'), tensor([ 3, 16, 10,  4, 16, 16, 16, 10, 16, 16, 13, 13, 16, 16, 16, 13,  7,  2,\n",
      "        11,  6, 16, 16, 19,  9,  6, 10,  8,  2, 16, 19, 16,  8],\n",
      "       device='cuda:0'), tensor([10, 10, 16,  5, 16,  8, 10, 13, 16, 16,  8, 13,  7, 16, 19, 18, 16,  3,\n",
      "         4, 16, 16, 16,  3, 16, 16, 16,  2,  2, 13, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16,  8, 16,  6, 16, 16, 13, 19,  3,  4, 16, 16, 10, 16, 16, 16, 16,  5,\n",
      "        16, 16,  5, 19, 10, 16,  8, 10, 16, 16, 16, 16, 10, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 10, 16, 16, 16, 11, 16, 10, 16, 16, 16, 16, 16, 16, 10, 18,\n",
      "         4, 15, 16, 16, 16,  4, 16, 16, 10, 16,  9,  8, 16, 16],\n",
      "       device='cuda:0'), tensor([11,  4, 16, 16, 16, 16, 16, 10,  8, 16,  6, 16,  5,  8,  4, 16,  5, 10,\n",
      "         4, 16, 10,  3,  4,  8, 16,  8,  6,  5, 16,  7,  8,  8],\n",
      "       device='cuda:0'), tensor([10, 16, 10,  8,  8,  8, 10, 16, 16,  2, 16, 10, 10, 16,  3, 16, 18,  8,\n",
      "         2,  4,  2, 10,  8,  4,  5, 13, 16, 10,  6,  8, 10, 16],\n",
      "       device='cuda:0'), tensor([10, 10,  5, 10, 16, 16,  2, 16,  5, 19, 10, 16, 10, 10,  9,  8, 16,  9,\n",
      "        16,  2,  4,  2,  8,  8,  2,  4,  2, 13, 16, 16,  4,  5],\n",
      "       device='cuda:0'), tensor([11,  5, 16, 10, 19,  5, 16,  2,  6, 16,  5, 16,  6,  8, 10, 16, 16,  2,\n",
      "        16, 16, 16,  5,  2,  5,  4,  4, 19,  9,  5, 16,  3, 16],\n",
      "       device='cuda:0'), tensor([13,  2, 16, 16, 16, 16,  8,  8, 16,  4, 10,  4, 16,  9, 16,  5,  8, 10,\n",
      "        16,  2, 19,  8, 16, 16, 16,  3,  8,  2,  5, 16, 10, 16],\n",
      "       device='cuda:0'), tensor([16, 10,  8,  2, 16, 16,  6, 16, 16, 16, 10, 16,  2, 16, 16,  3, 16, 10,\n",
      "        16,  5, 16, 16, 10, 16, 16, 16, 16,  3, 16, 16,  3, 16],\n",
      "       device='cuda:0'), tensor([16,  6, 16, 13,  2,  2, 16,  2, 10, 16,  8, 16, 16, 16, 16, 16, 16,  3,\n",
      "        16, 16,  4, 16,  3, 11,  8, 16, 16, 16, 13, 16, 16, 10],\n",
      "       device='cuda:0'), tensor([ 4, 16, 16, 10,  4, 16, 16,  8, 16, 16,  4, 13,  2, 16, 11, 16, 10, 16,\n",
      "        16, 16, 16, 10, 16, 10, 16, 16, 16,  2,  3, 13,  8,  4],\n",
      "       device='cuda:0'), tensor([ 9,  0, 16, 16, 16, 19, 10,  4,  2,  8,  5, 10,  0,  2, 16,  2,  2,  4,\n",
      "        19, 16,  9,  2,  9, 11,  2, 16,  5, 16, 16, 11,  2, 10],\n",
      "       device='cuda:0'), tensor([ 5,  2,  4, 10,  2, 16, 19, 13,  2,  8, 10,  5,  9,  8,  9,  5,  6, 16,\n",
      "         4,  4,  9,  2, 16,  8, 16,  4, 19,  9, 13, 16,  7, 10],\n",
      "       device='cuda:0'), tensor([ 3,  8,  8, 16, 13, 16,  6,  2, 16,  9,  8,  2,  8, 16,  8,  2,  9,  5,\n",
      "        13,  2,  9, 10,  5,  8,  2,  8, 10,  8, 10, 16, 16, 10],\n",
      "       device='cuda:0'), tensor([16, 10,  4,  9, 19, 11,  8, 16,  2, 10, 16,  4,  8,  4, 13, 18,  8, 16,\n",
      "         8,  9,  6, 16,  4, 16,  2,  5,  2,  1, 16, 16, 16, 19],\n",
      "       device='cuda:0'), tensor([16, 16,  3,  9, 19,  8, 10,  0, 19,  7, 13, 16,  4, 16,  4,  4, 16, 10,\n",
      "        16,  6, 16, 16,  8,  8,  8, 16, 16, 16, 16, 16,  4, 16],\n",
      "       device='cuda:0'), tensor([19,  4,  2, 10, 16, 16,  2,  9,  5,  4, 16, 16, 10, 16, 16, 10,  4, 16,\n",
      "         8,  8,  8, 16, 10,  2,  8, 16, 16,  5, 16, 10,  9,  4],\n",
      "       device='cuda:0'), tensor([10,  6, 17, 16,  8, 16, 16, 16,  8,  4, 10,  4,  0, 16, 10,  2,  5, 16,\n",
      "         8, 16, 13, 10, 16, 16,  8, 19, 16, 11, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([ 1, 13, 16, 16,  5,  9, 18, 18,  4,  9, 13,  8, 16,  3,  5, 16,  4,  6,\n",
      "         8, 16,  5, 16, 16, 16, 16, 16,  1, 16,  9, 19,  8,  5],\n",
      "       device='cuda:0'), tensor([16,  2, 10,  7, 16, 16, 16, 16, 10,  4, 16, 16, 13, 16, 16,  8,  8, 18,\n",
      "        13,  8,  5, 16,  4, 16, 16, 13, 16,  2,  4,  8,  3, 16],\n",
      "       device='cuda:0'), tensor([ 4, 16, 16, 16, 10,  9, 10, 16, 16, 16,  8,  4, 16,  5, 16,  6, 16, 19,\n",
      "         2,  7, 16,  5, 16,  5, 16, 16, 16, 19,  8,  8,  4, 16],\n",
      "       device='cuda:0'), tensor([ 4, 19, 16, 16, 16, 16, 15,  4, 16, 16, 16,  5,  9,  4, 16, 16, 13,  5,\n",
      "        19,  4,  5, 16, 16, 16, 16, 16, 16, 14,  3,  2,  8,  8],\n",
      "       device='cuda:0'), tensor([16, 16,  8, 10, 16,  9,  4,  9,  4,  4,  8,  2, 16, 11, 14, 16, 16,  9,\n",
      "         3, 19,  3,  5,  4, 16, 19, 10,  2, 17, 16,  2, 16,  4],\n",
      "       device='cuda:0'), tensor([16,  8, 10, 16,  4, 16,  9,  8, 16,  4,  8, 16, 10,  9,  2,  9, 16, 15,\n",
      "        14,  7,  8, 13, 16, 16, 10,  2, 19, 16,  3,  2,  8,  5],\n",
      "       device='cuda:0'), tensor([10,  4, 16, 16, 13, 10, 10, 10, 10, 10, 16, 13, 10, 16, 16, 10, 16, 16,\n",
      "        16, 14, 16, 10, 16, 10,  5, 16, 19, 16,  5,  8, 16,  4],\n",
      "       device='cuda:0'), tensor([16, 10, 10,  9,  5, 18,  4,  8,  0, 13,  9, 17, 19, 16, 10, 16, 16,  5,\n",
      "         4, 19, 11, 10,  9,  5, 10, 16,  2, 10,  2,  4,  3, 10],\n",
      "       device='cuda:0'), tensor([ 8,  5, 16, 16, 13, 10,  3,  3, 10,  5, 16, 10, 16, 16, 16,  6,  8, 16,\n",
      "         6,  4, 16, 16, 16,  5,  8, 13,  4, 16, 16, 10, 16,  8],\n",
      "       device='cuda:0'), tensor([ 3, 16,  9, 16,  1, 13,  3, 16,  5, 10,  8, 16,  4,  4, 13, 16, 16,  4,\n",
      "        16, 19, 16,  5,  4, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
      "       device='cuda:0'), tensor([16, 16, 16, 16,  2,  5, 18, 16, 16, 16, 16, 16, 10,  5, 16, 16, 16, 16,\n",
      "         4, 10,  4,  8], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "listOfList = [list(x.cpu().numpy()) for x in predictions]\n",
    "result = [item for sublist in listOfList for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 8,\n",
       " 10,\n",
       " 5,\n",
       " 19,\n",
       " 15,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 16,\n",
       " 10,\n",
       " 9,\n",
       " 0,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 19,\n",
       " 11,\n",
       " 8,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 19,\n",
       " 2,\n",
       " 19,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 8,\n",
       " 14,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 13,\n",
       " 9,\n",
       " 19,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 16,\n",
       " 10,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 19,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 10,\n",
       " 11,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 16,\n",
       " 9,\n",
       " 4,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 2,\n",
       " 13,\n",
       " 3,\n",
       " 8,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 13,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 16,\n",
       " 4,\n",
       " 10,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 8,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 6,\n",
       " 16,\n",
       " 13,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 16,\n",
       " 8,\n",
       " 3,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 13,\n",
       " 0,\n",
       " 18,\n",
       " 16,\n",
       " 4,\n",
       " 2,\n",
       " 10,\n",
       " 10,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 15,\n",
       " 3,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 8,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 4,\n",
       " 19,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 16,\n",
       " 13,\n",
       " 6,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 11,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 7,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 13,\n",
       " 11,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 13,\n",
       " 2,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 16,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 16,\n",
       " 9,\n",
       " 16,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 16,\n",
       " 9,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 11,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 10,\n",
       " 4,\n",
       " 16,\n",
       " 2,\n",
       " 10,\n",
       " 3,\n",
       " 3,\n",
       " 16,\n",
       " 8,\n",
       " 5,\n",
       " 16,\n",
       " 8,\n",
       " 5,\n",
       " 11,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 10,\n",
       " 10,\n",
       " 19,\n",
       " 2,\n",
       " 19,\n",
       " 2,\n",
       " 11,\n",
       " 16,\n",
       " 2,\n",
       " 13,\n",
       " 11,\n",
       " 15,\n",
       " 2,\n",
       " 13,\n",
       " 16,\n",
       " 4,\n",
       " 10,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 3,\n",
       " 2,\n",
       " 10,\n",
       " 5,\n",
       " 10,\n",
       " 6,\n",
       " 13,\n",
       " 4,\n",
       " 9,\n",
       " 16,\n",
       " 4,\n",
       " 10,\n",
       " 2,\n",
       " 8,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 16,\n",
       " 5,\n",
       " 5,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 16,\n",
       " 9,\n",
       " 3,\n",
       " 10,\n",
       " 5,\n",
       " 2,\n",
       " 16,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 10,\n",
       " 13,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 11,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 16,\n",
       " 4,\n",
       " 8,\n",
       " 16,\n",
       " 0,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 6,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 4,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 3,\n",
       " 1,\n",
       " 16,\n",
       " 4,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 10,\n",
       " 10,\n",
       " 16,\n",
       " 10,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 10,\n",
       " 2,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 4,\n",
       " 9,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 9,\n",
       " 2,\n",
       " 15,\n",
       " 6,\n",
       " 10,\n",
       " 13,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 16,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 10,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 13,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 14,\n",
       " 2,\n",
       " 0,\n",
       " 19,\n",
       " 8,\n",
       " 13,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 16,\n",
       " 3,\n",
       " 6,\n",
       " 11,\n",
       " 8,\n",
       " 9,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 19,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 16,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 15,\n",
       " 10,\n",
       " 8,\n",
       " 16,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 10,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 13,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 13,\n",
       " 9,\n",
       " 5,\n",
       " 18,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 5,\n",
       " 9,\n",
       " 16,\n",
       " 0,\n",
       " 16,\n",
       " 18,\n",
       " 2,\n",
       " 0,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 10,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 16,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 13,\n",
       " 19,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 8,\n",
       " 19,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 16,\n",
       " 13,\n",
       " 9,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 5,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 9,\n",
       " 16,\n",
       " 6,\n",
       " 10,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 19,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 18,\n",
       " 16,\n",
       " 19,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 8,\n",
       " 14,\n",
       " 16,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 16,\n",
       " 4,\n",
       " 5,\n",
       " 16,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 10,\n",
       " 13,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 9,\n",
       " 16,\n",
       " 16,\n",
       " 7,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 6,\n",
       " 16,\n",
       " 19,\n",
       " 5,\n",
       " 10,\n",
       " 19,\n",
       " 4,\n",
       " 5,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 9,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 6,\n",
       " 16,\n",
       " 2,\n",
       " 4,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 10,\n",
       " 13,\n",
       " 5,\n",
       " 16,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 3,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 13,\n",
       " 16,\n",
       " 10,\n",
       " 8,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 6,\n",
       " 1,\n",
       " 16,\n",
       " 4,\n",
       " 10,\n",
       " 11,\n",
       " 13,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 6,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 11,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 13,\n",
       " 4,\n",
       " 5,\n",
       " 16,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 16,\n",
       " 4,\n",
       " 8,\n",
       " 19,\n",
       " 4,\n",
       " 5,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 10,\n",
       " 15,\n",
       " 16,\n",
       " 10,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 19,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 5,\n",
       " 16,\n",
       " 13,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 19,\n",
       " 10,\n",
       " 17,\n",
       " 2,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 9,\n",
       " 10,\n",
       " 19,\n",
       " 2,\n",
       " 4,\n",
       " 10,\n",
       " 8,\n",
       " 4,\n",
       " 10,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 13,\n",
       " 16,\n",
       " 10,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 8,\n",
       " 19,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 19,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 19,\n",
       " 10,\n",
       " 10,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 15,\n",
       " 4,\n",
       " 16,\n",
       " 6,\n",
       " 2,\n",
       " 19,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 16,\n",
       " 2,\n",
       " 19,\n",
       " 16,\n",
       " 10,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 14,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 3,\n",
       " 6,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 16,\n",
       " 16,\n",
       " 9,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 11,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 5,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 10,\n",
       " 4,\n",
       " 16,\n",
       " 4,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample\n",
    "submission['label'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137832</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137833</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137834</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137836</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137837</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13713</th>\n",
       "      <td>169336</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13714</th>\n",
       "      <td>169338</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13715</th>\n",
       "      <td>169340</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13716</th>\n",
       "      <td>169341</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13717</th>\n",
       "      <td>169342</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13718 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  label\n",
       "0      137832     16\n",
       "1      137833      8\n",
       "2      137834     10\n",
       "3      137836      5\n",
       "4      137837     19\n",
       "...       ...    ...\n",
       "13713  169336     16\n",
       "13714  169338      4\n",
       "13715  169340     10\n",
       "13716  169341      4\n",
       "13717  169342      8\n",
       "\n",
       "[13718 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of things left to experiment and fine tune\n",
    "# 1. train bert with abstract only\n",
    "# 2. train bert with title and abstract\n",
    "# 3. train bert with batch size at 16 or 32\n",
    "# 4. Tweak the max length for padding depending on the distribution length of the paragraphs\n",
    "## 5. Very important: also try with 4 epochs\n",
    "## Play with the drop out level at 0.2, 0.3, and 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
